{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import urllib\n",
    "import bz2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import plotly.graph_objs as go\n",
    "import os\n",
    "from utils.utils_IO import ordered_arr_3d_to_dict, refill_nan_array, arr_2d_to_list_of_dicts, read_image, make_image_array, revert_ordered_arr_2d_to_dict, save_object, write_video\n",
    "from utils.utils_plotting import plot_image_labels, plot_3d_points, vector_plot, draw_circles, slope, drawLine, skew, plot_cams_and_points\n",
    "from utils.utils_BA import fun, bundle_adjustment_sparsity, project\n",
    "from anipose_BA import CameraGroup, Camera\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from pathlib import Path\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "\n",
    "def GetXYs(eid, video_type, trial_range):\n",
    "    '''\n",
    "    eid: session id, e.g. '3663d82b-f197-4e8b-b299-7b803a155b84'\n",
    "    video_type: one of 'left', 'right', 'body'\n",
    "    trial_range: first and last trial number of range to be shown, e.g. [5,7]\n",
    "    '''\n",
    " \n",
    "    one = ONE()\n",
    "    dataset_types = ['camera.times',\n",
    "                     'trials.intervals',\n",
    "                     'camera.dlc']\n",
    "\n",
    "    a = one.list(eid, 'dataset-types')\n",
    "\n",
    "    assert all([i in a for i in dataset_types]\n",
    "               ), 'For this eid, not all data available'\n",
    "\n",
    "    D = one.load(eid, dataset_types=dataset_types, dclass_output=True)\n",
    "    alf_path = Path(D.local_path[0]).parent.parent / 'alf'\n",
    "\n",
    "    video_data = alf_path.parent / 'raw_video_data'     \n",
    "    video_path = list(video_data.rglob('_iblrig_%sCamera.raw.*' % video_type))[0] \n",
    "    print(video_path) \n",
    "\n",
    "    # that gives cam time stamps and DLC output (change to alf_path eventually)\n",
    "    \n",
    "    cam1 = alf.io.load_object(video_path.parent, '_ibl_%sCamera' % video_type)     \n",
    "    try:\n",
    "        cam0 = alf.io.load_object(alf_path, '_ibl_%sCamera' % video_type)          \n",
    "    except:\n",
    "        cam0 = {}    \n",
    "    cam = {**cam0,**cam1}\n",
    "\n",
    "    # just to read in times for newer data (which has DLC results in pqt format\n",
    "    #cam = alf.io.load_object(alf_path, '_ibl_%sCamera' % video_type)\n",
    "\n",
    "    # pick trial range for which to display stuff\n",
    "    trials = alf.io.load_object(alf_path, '_ibl_trials')\n",
    "    num_trials = len(trials['intervals'])\n",
    "    if trial_range[-1] > num_trials - 1:\n",
    "        print('There are only %s trials' % num_trials)\n",
    "\n",
    "    frame_start = find_nearest(cam['times'],\n",
    "                               [trials['intervals'][trial_range[0]][0]])\n",
    "    frame_stop = find_nearest(cam['times'],\n",
    "                              [trials['intervals'][trial_range[-1]][1]])\n",
    "\n",
    "    '''\n",
    "    DLC related stuff\n",
    "    '''\n",
    "    Times = cam['times'][frame_start:frame_stop] \n",
    "    del cam['times']      \n",
    "\n",
    "#    dlc_name = '_ibl_%sCamera.dlc.pqt' % video_type\n",
    "#    dlc_path = alf_path / dlc_name\n",
    "#    cam=pd.read_parquet(dlc_path)    \n",
    "\n",
    "\n",
    "    points = np.unique(['_'.join(x.split('_')[:-1]) for x in cam.keys()])\n",
    "    \n",
    "\n",
    "    if video_type != 'body':\n",
    "        d = list(points) \n",
    "        d.remove('tube_top')\n",
    "        d.remove('tube_bottom')   \n",
    "        points = np.array(d)\n",
    "\n",
    "\n",
    "    # Set values to nan if likelyhood is too low # for pqt: .to_numpy()\n",
    "    XYs = {}\n",
    "    for point in points:\n",
    "        x = np.ma.masked_where(\n",
    "            cam[point + '_likelihood'] < 0.9, cam[point + '_x'])\n",
    "        x = x.filled(np.nan)\n",
    "        y = np.ma.masked_where(\n",
    "            cam[point + '_likelihood'] < 0.9, cam[point + '_y'])\n",
    "        y = y.filled(np.nan)\n",
    "        XYs[point] = np.array(\n",
    "            [x[frame_start:frame_stop], y[frame_start:frame_stop]])\n",
    "            \n",
    "    res_folder = '/home/mic/3D-Animal-Pose-master/IBL_example/%s_trials_%s_%s' %(eid, trial_range[0], trial_range[1])    \n",
    "    \n",
    "    Path(res_folder).mkdir(parents=True, exist_ok=True)    \n",
    "            \n",
    "    np.save('/home/mic/3D-Animal-Pose-master/IBL_example/%s_trials_%s_%s/XYs_%s.npy' %(eid, trial_range[0], trial_range[1], video_type), XYs)\n",
    "    np.save('/home/mic/3D-Animal-Pose-master/IBL_example/%s_trials_%s_%s/times_%s.npy' %(eid, trial_range[0], trial_range[1], video_type), Times)\n",
    "    #return XYs, Times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#eid = 'cb2ad999-a6cb-42ff-bf71-1774c57e5308'\n",
    "eid = 'e5fae088-ed96-4d9b-82f9-dfd13c259d52'\n",
    "#trial_range = [5,7]\n",
    "trial_range = [10,13]\n",
    "res_folder = '/Users/Sunsmeister/Desktop/Research/Brain/MultiView/3D-Animal-Pose/data/IBL_example/%s_trials_%s_%s' %(eid, trial_range[0], trial_range[1])\n",
    "XYs_left = np.load(res_folder + '/XYs_left.npy', allow_pickle=True).flatten()[0]\n",
    "XYs_right = np.load(res_folder + '/XYs_right.npy', allow_pickle=True).flatten()[0]\n",
    "\n",
    "times_left = np.load(res_folder + '/times_left.npy')\n",
    "times_right = np.load(res_folder + '/times_right.npy')\n",
    "\n",
    "# get closest stamps or right cam (150 Hz) for each stamp of left (60 Hz)\n",
    "idx_aligned = []\n",
    "for t in times_left:\n",
    "    idx_aligned.append(find_nearest(times_right, t))\n",
    "    \n",
    "# paw_l in video left = paw_r in video right\n",
    "# Divide left coordinates by 2 to get them in half resolution like right cam; \n",
    "# reduce temporal resolution of right cam to that of left cam\n",
    "num_analyzed_body_parts = 3  # both paws and nose\n",
    "\n",
    "cam_right_paw1 = np.array([XYs_right['paw_r'][0][idx_aligned], XYs_right['paw_r'][1][idx_aligned]]) \n",
    "cam_left_paw1 = np.array([XYs_left['paw_l'][0]/2,XYs_left['paw_l'][1]/2]) \n",
    "\n",
    "cam_right_paw2 = np.array([XYs_right['paw_l'][0][idx_aligned], XYs_right['paw_l'][1][idx_aligned]]) \n",
    "cam_left_paw2 = np.array([XYs_left['paw_r'][0]/2,XYs_left['paw_r'][1]/2]) \n",
    "\n",
    "cam_right_nose = np.array([XYs_right['nose_tip'][0][idx_aligned], XYs_right['nose_tip'][1][idx_aligned]]) \n",
    "cam_left_nose = np.array([XYs_left['nose_tip'][0]/2,XYs_left['nose_tip'][1]/2]) \n",
    "\n",
    "# the format shall be such that points are concatenated, p1,p2,p3,p1,p2,p3, ... \n",
    "cam1 = np.zeros((len(idx_aligned) * num_analyzed_body_parts, 2)) \n",
    "cam1[0::3] = cam_right_paw1.T\n",
    "cam1[1::3] = cam_right_paw2.T\n",
    "cam1[2::3] = cam_right_nose.T\n",
    "\n",
    "cam2 = np.zeros((len(idx_aligned) * num_analyzed_body_parts, 2)) \n",
    "cam2[0::3] = cam_left_paw1.T\n",
    "cam2[1::3] = cam_left_paw2.T\n",
    "cam2[2::3] = cam_left_nose.T\n",
    "\n",
    "pts_array_2d_with_nans = np.array([cam1,cam2])\n",
    "\n",
    "num_cameras, num_points_all, _ = pts_array_2d_with_nans.shape\n",
    "\n",
    "# remove nans (any of the x_r,y_r, x_l, y_l) and keep clean_point_indices\n",
    "non_nan_idc = ~np.isnan(pts_array_2d_with_nans).any(axis=2).any(axis=0)\n",
    "\n",
    "info_dict = {}\n",
    "info_dict['num_frames'] = len(times_left) \n",
    "info_dict['num_cameras'] = num_cameras\n",
    "info_dict['num_analyzed_body_parts'] = num_analyzed_body_parts \n",
    "info_dict['num_points_all'] = num_points_all\n",
    "info_dict['clean_point_indices'] = np.arange(num_points_all)[non_nan_idc]\n",
    "\n",
    "print(info_dict)\n",
    "\n",
    "pts_array_2d = pts_array_2d_with_nans[:,info_dict['clean_point_indices']]\n",
    "\n",
    "IMG_WIDTH = 640\n",
    "IMG_HEIGHT = 512\n",
    "P_X_TOP = P_X_BOT = IMG_WIDTH // 2\n",
    "P_Y_TOP = P_Y_BOT = IMG_HEIGHT // 2\n",
    "TOP_IMG_HEIGHT = IMG_HEIGHT\n",
    "BOT_IMG_HEIGHT = IMG_HEIGHT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def sorted_nicely(l):\n",
    "    \"\"\" Sort the given iterable in the way that humans expect.\"\"\"\n",
    "    convert = lambda text: int(text) if text.isdigit() else text\n",
    "    alphanum_key = lambda key: [convert(c) for c in re.split(\"([0-9]+)\", key)]\n",
    "    return sorted(l, key=alphanum_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "left_path = Path(f'/Users/Sunsmeister/Desktop/Research/Brain/MultiView/3D-Animal-Pose/data/IBL_example/{eid}_trials_{trial_range[0]}_{trial_range[1]}/imgs_left')\n",
    "right_path = Path(f'/Users/Sunsmeister/Desktop/Research/Brain/MultiView/3D-Animal-Pose/data/IBL_example/{eid}_trials_{trial_range[0]}_{trial_range[1]}/imgs_right')\n",
    "left_frames = sorted_nicely(os.listdir(left_path))\n",
    "left_frames.append(left_frames[-1])\n",
    "left_frames = [left_path / i for i in left_frames]\n",
    "right_frames = sorted_nicely(os.listdir(right_path))\n",
    "right_frames.append(right_frames[-1])\n",
    "right_frames = [right_path / i for i in right_frames]\n",
    "\n",
    "path_images = [left_frames, right_frames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(info_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements for Bundle Adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "`P_{X,Y}_{TOP,BOT}`: (int) - {width / 2, height / 2} for camera {1,2}\n",
    "\n",
    "-->For setting the offset terms in the camera matrix to the center of the image plane\n",
    "\n",
    "\n",
    "`pts_array_2d`: (np.array) - Array of shape (num_cameras, num_points, 2) containing set of 2d points for each camera. This should be after cleaning NaNs i.e. removing rows with NaNs\n",
    "\n",
    "`info_dict`: Dictionary with keys {'num_frames', 'num_analyzed_body_parts', 'num_cameras', 'num_points_all', 'clean_point_indices'}\n",
    "\n",
    "--> 'num_frames' is the number of frames in the video\n",
    "\n",
    "--> 'num_analyzed_body_parts' is the number of body parts / joints being modeled (i.e. one per keypoint)\n",
    "\n",
    "--> 'num_cameras' is the number of cameras. In our case, it is 2\n",
    "\n",
    "--> 'num_points_all' is the original number of points (including NaNs)\n",
    "\n",
    "--> 'clean_point_indices' is a list of indices (with length = num_points in `pts_array_2d`) pointing to the clean (non-NaN) entries in the original data\n",
    "\n",
    "`path_images`: (list) - List of sublists. Each sublist (one per camera / view) contains absolute paths to image frames. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "def save_object(obj, filename, objects_dir='./rick_data_objects/'):\n",
    "    with open(Path(objects_dir) / filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_object(filename, objects_dir='./rick_data_objects/'):\n",
    "    obj = None\n",
    "    with open(Path(objects_dir) / filename, 'rb') as input:\n",
    "        obj = pickle.load(input)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "save_object(info_dict, 'info_dict.pkl')\n",
    "save_object(pts_array_2d, 'pts_array_2d.pkl')\n",
    "offsets = [P_X_TOP, P_Y_TOP, P_X_BOT, P_Y_BOT]\n",
    "save_object(offsets, 'offsets.pkl')\n",
    "save_object(path_images, 'path_images.pkl')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#Load\n",
    "info_dict = load_object('info_dict.pkl')\n",
    "pts_array_2d = load_object('pts_array_2d.pkl')\n",
    "offsets = load_object('offsets.pkl')\n",
    "path_images = load_object('path_images.pkl')\n",
    "[P_X_TOP, P_Y_TOP, P_X_BOT, P_Y_BOT] = offsets\n",
    "IMG_WIDTH = P_X_TOP * 2\n",
    "TOP_IMG_HEIGHT = P_Y_TOP * 2\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bundle Adjust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--------CAMERA 1------------\n",
    "#Initialize camera 1\n",
    "camera_1 = Camera(rvec=[0,0,0], tvec=[0,0,0])\n",
    "#Set offset\n",
    "camera_1.set_size((P_X_TOP, P_Y_TOP))\n",
    "\n",
    "cam1_init_params = np.abs(np.random.rand(8))\n",
    "#Set rotations [0:3] and translation [3:6] to 0\n",
    "cam1_init_params[0:6] = 0\n",
    "#Initialize focal length to image width\n",
    "cam1_init_params[6] = P_X_TOP * 2\n",
    "#Initialize distortion to 0\n",
    "cam1_init_params[7] = 0.0 \n",
    "#Set parameters\n",
    "camera_1.set_params(cam1_init_params)\n",
    "\n",
    "#--------CAMERA 2------------\n",
    "'''\n",
    "#Set rotation vector w.r.t. camera 1\n",
    "rvec2 = np.pi/2 * np.array([1, 0, 0])\n",
    "#Set translation vector w.r.t. camera 1\\\n",
    "tvec2 = [0, 1, 1]\n",
    "#Initialize camera 2\n",
    "camera_2 = Camera(rvec=rvec2, tvec=tvec2)\n",
    "#Set offset \n",
    "camera_1.set_size((P_X_BOT, P_Y_BOT))\n",
    "\n",
    "cam2_init_params = np.abs(np.random.rand(8))\n",
    "cam2_init_params[0:3] = rvec2\n",
    "cam2_init_params[3:6] = tvec2\n",
    "cam2_init_params[6] = P_X_BOT * 2\n",
    "cam2_init_params[7] = 0.0\n",
    "camera_2.set_params(cam2_init_params)\n",
    "'''\n",
    "#Set rotation vector w.r.t. camera 1\n",
    "# roration around y axis only, about 120 deg (2.0127 rad) from Guido's CAD\n",
    "rvec2 = np.array([0, 2.0127, 0])\n",
    "\n",
    "\n",
    "#Set translation vector w.r.t. camera 1, using CAD drawing [mm];\n",
    "# cameras are 292.8 mm apart; \n",
    "#distance vector pointing from cam1 to the other cam: \n",
    "tvec2 = [-1.5664, 0, 2.4738]\n",
    "#Initialize camera 2\n",
    "camera_2 = Camera(rvec=rvec2, tvec=tvec2)\n",
    "#Set offset \n",
    "camera_1.set_size((P_X_BOT, P_Y_BOT))\n",
    "\n",
    "cam2_init_params = np.abs(np.random.rand(8))\n",
    "cam2_init_params[0:3] = rvec2\n",
    "cam2_init_params[3:6] = tvec2\n",
    "cam2_init_params[6] = P_X_BOT * 2\n",
    "cam2_init_params[7] = 0.0\n",
    "camera_2.set_params(cam2_init_params)\n",
    "\n",
    "#Group cameras\n",
    "cam_group = CameraGroup(cameras=[camera_1, camera_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Get error before Bundle Adjustment by triangulating using the initial parameters:\n",
    "f0, points_3d_init = cam_group.get_initial_error(pts_array_2d)\n",
    "print(points_3d_init.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plot_cams_and_points(cam_group=cam_group, points_3d=points_3d_init, title=\"3D Points Initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Run Bundle Adjustment\n",
    "res, points_3d = cam_group.bundle_adjust(pts_array_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_cams_and_points(cam_group=cam_group, points_3d=points_3d, title=\"3D Points Bundle Adjusted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Get projected points\n",
    "points_proj_1 = camera_1.project(points_3d, ).squeeze()\n",
    "points_proj_2 = camera_2.project(points_3d).squeeze()\n",
    "points_proj = np.concatenate((points_proj_1, points_proj_2), axis=0)\n",
    "print('f_1: ', camera_1.get_focal_length())\n",
    "print('f_2: ', camera_2.get_focal_length())\n",
    "print('dist_1: ', camera_1.get_distortions())\n",
    "print('dist_2: ', camera_2.get_distortions())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_folder = 'rick_plots'\n",
    "if not os.path.exists(plot_folder):\n",
    "    os.makedirs(plot_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(f0, label = 'pre optim, random init')\n",
    "plt.plot(res.fun, label = 'after optim')\n",
    "plt.legend()\n",
    "plt.ylabel('coordinate-wise signed reproj-error')\n",
    "plt.title('reprojection error before and after optim')\n",
    "plt.savefig(os.path.join(plot_folder,'reproj-err-per-frame-initdlc3d.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now we first refill the full sized containers, then revert to dicts.\n",
    "\n",
    "# do the pts_array_3d_clean\n",
    "array_3d_back = refill_nan_array(points_3d, \n",
    "                               info_dict, \n",
    "                               dimension = '3d')\n",
    "pose_dict_3d_refill = ordered_arr_3d_to_dict(array_3d_back, info_dict)\n",
    "\n",
    "# pts_3d_BA\n",
    "BA_array_3d_back = refill_nan_array(points_3d, \n",
    "                               info_dict, \n",
    "                               dimension = '3d')\n",
    "BA_dict = ordered_arr_3d_to_dict(BA_array_3d_back, info_dict)\n",
    "\n",
    "# pts_2d_orig\n",
    "pts_array_2d_og = np.reshape(pts_array_2d, (pts_array_2d.shape[0] * pts_array_2d.shape[1], -1))\n",
    "array_2d_orig = refill_nan_array(pts_array_2d_og, \n",
    "                              info_dict, \n",
    "                               dimension = '2d')\n",
    "pose_list_2d_orig = arr_2d_to_list_of_dicts(array_2d_orig,\n",
    "                                              info_dict)\n",
    "                                              \n",
    "# pts_2d_reproj\n",
    "array_2d_reproj_back = refill_nan_array(points_proj, \n",
    "                              info_dict, \n",
    "                               dimension = '2d')\n",
    "pose_list_2d_reproj = arr_2d_to_list_of_dicts(array_2d_reproj_back,\n",
    "                                              info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joined_list_2d = pose_list_2d_orig + pose_list_2d_reproj\n",
    "joined_list_3d = []\n",
    "joined_list_3d.append(pose_dict_3d_refill)\n",
    "joined_list_3d.append(BA_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Red = ground truth, blue = proj\n",
    "color_list_2d = ['red', 'red', 'blue', 'blue']\n",
    "color_list_3d = ['red', 'blue']\n",
    "# set limits to be the maximum of the two plots\n",
    "# we are padding the limits of the axis since some points lie at the border.\n",
    "pad = 1\n",
    "lims = {}\n",
    "x_min = np.nanmin(BA_dict['x_coords'])\n",
    "x_max = np.nanmax(BA_dict['x_coords'])\n",
    "y_min = np.nanmin(BA_dict['y_coords'])\n",
    "y_max = np.nanmax(BA_dict['y_coords'])\n",
    "z_min = np.nanmin(BA_dict['z_coords'])\n",
    "z_max = np.nanmax(BA_dict['z_coords'])\n",
    "lims['x'] = [x_min, x_max]\n",
    "lims['y'] = [y_min, y_max]\n",
    "lims['z'] = [z_min, z_max]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_start = 155\n",
    "ind_end = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### 3d plot\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import mpl_toolkits.mplot3d.axes3d as p3\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(constrained_layout=True, figsize = (12,6))\n",
    "gs = GridSpec(2, 2, figure=fig)\n",
    "ax1 = fig.add_subplot(gs[:2, 0])\n",
    "ax2 = fig.add_subplot(gs[:2, 1], projection = '3d') # https://matplotlib.org/3.1.1/gallery/mplot3d/subplot3d.html\n",
    "image_folder = 'images_test'\n",
    "if not os.path.exists(image_folder):\n",
    "    os.makedirs(image_folder)\n",
    "\n",
    "ax2.view_init(elev=0, azim=90) # see https://stackoverflow.com/questions/12904912/how-to-set-camera-position-for-3d-plots-using-python-matplotlib\n",
    "\n",
    "#FRONT RIGHT PAW\n",
    "for i in range(ind_start,ind_end):\n",
    "    # clear both ax1 and ax2\n",
    "    ax1.cla()\n",
    "    ax2.cla()   \n",
    "    # load image\n",
    "    img_1 = read_image(path_images[0][i], flip=False)\n",
    "    img_2 = read_image(path_images[1][i], flip=False)\n",
    "    img = np.concatenate((img_1, img_2), axis=0)\n",
    "    plot_image_labels(img,\\\n",
    "                        joined_list_2d,\n",
    "                        i,\n",
    "                        color_list_2d,\n",
    "                        ax = ax1, top_img_height=TOP_IMG_HEIGHT)\n",
    "    \n",
    "    ax2.azim += 1\n",
    "    plot_3d_points(joined_list_3d,\n",
    "                   lims,\n",
    "                   i,\n",
    "                   color_list_3d,\n",
    "                   ax=ax2)\n",
    "    im_int = str('%.5i' % i)\n",
    "    plt.savefig(image_folder + '/' + 'im' + im_int + '.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_video(image_dir='./images_test/', out_file='reconstruction.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Bundle Adjusted Through Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get axis lims\n",
    "x_min = np.nanmin(BA_dict['x_coords'])\n",
    "x_max = np.nanmax(BA_dict['x_coords'])\n",
    "y_min = np.nanmin(BA_dict['y_coords'])\n",
    "y_max = np.nanmax(BA_dict['y_coords'])\n",
    "z_min = np.nanmin(BA_dict['z_coords'])\n",
    "z_max = np.nanmax(BA_dict['z_coords'])\n",
    "scene_lims = [[x_min,x_max], [y_min,y_max], [z_min,z_max]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_dir = Path('./3d_point_plots/')\n",
    "plot_dir.mkdir(exist_ok=True, parents=True)\n",
    "for i in range(ind_start, ind_end):\n",
    "    slice_3d = np.asarray([BA_dict['x_coords'][i], BA_dict['y_coords'][i],BA_dict['z_coords'][i]]).transpose()\n",
    "    fig = plot_cams_and_points(points_3d=slice_3d, scene_lims=None, point_size=5, scene_aspect='cube', show_plot=False, title=\"3D Points Through Time\")\n",
    "    fig.write_image(str(plot_dir / f\"points_{i}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_video(image_dir=plot_dir, out_file=\"points_through_time.mp4\")"
   ]
  },
  {
   "source": [
    "# Plot Skeleton"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### 3d plot\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "%matplotlib inline\n",
    "plot_dir = Path('./3d_point_plots/')\n",
    "\n",
    "fig = plt.figure(constrained_layout=True, figsize = (12,6))\n",
    "gs = GridSpec(1, 1, figure=fig)\n",
    "ax1 = fig.add_subplot(gs[:2, 0])\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)\n",
    "\n",
    "\n",
    "for i in range(ind_start,ind_end):\n",
    "    # clear both ax1 and ax2\n",
    "    ax1.cla()\n",
    "    # load image\n",
    "    img_1 = read_image(path_images[0][i], flip=False)\n",
    "    img_2 = read_image(path_images[1][i], flip=False)\n",
    "    img = np.concatenate((img_1, img_2), axis=0)\n",
    "\n",
    "    plot_image_labels(img,\\\n",
    "                        joined_list_2d,\n",
    "                        i,\n",
    "                        color_list_2d,\n",
    "                        ax = ax1, top_img_height=TOP_IMG_HEIGHT)\n",
    "\n",
    "    im_int = str('%.5i' % i)\n",
    "    plt.savefig(str(plot_dir / ('im' + im_int + '.png')),bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#['nose', 'paw1LH', 'paw2LF', 'paw3RF', 'paw4RH', 'tailBase', 'tailMid']\n",
    "#0: nose\n",
    "#1: left front paw\n",
    "#2: left back paw\n",
    "#3: right back paw\n",
    "#4: right front\n",
    "#5: tail base\n",
    "#6: tail mid"
   ]
  },
  {
   "source": [
    "#Plot skeleton\n",
    "from PIL import Image\n",
    "\n",
    "for i in range(ind_start, ind_end):\n",
    "    im_int = str('%.5i' % i)\n",
    "    proj_im_path = plot_dir / f\"im{im_int}.png\"\n",
    "    proj_img = Image.open(proj_im_path)\n",
    "    width, height = proj_img.size\n",
    "\n",
    "    slice_3d = np.asarray([BA_dict['x_coords'][i], BA_dict['y_coords'][i],BA_dict['z_coords'][i]]).transpose()\n",
    "    \n",
    "    #Add coordinates of each bodypart to dict\n",
    "    skeleton_bp = {}\n",
    "    skeleton_bp['nose'] = (BA_dict['x_coords'][i][2], BA_dict['y_coords'][i][2], BA_dict['z_coords'][i][2])\n",
    "    skeleton_bp['paw1'] = (BA_dict['x_coords'][i][0], BA_dict['y_coords'][i][0], BA_dict['z_coords'][i][0])\n",
    "    skeleton_bp['paw2'] = (BA_dict['x_coords'][i][1], BA_dict['y_coords'][i][1], BA_dict['z_coords'][i][1])\n",
    "\n",
    "    #Now, define lines:\n",
    "    #List of tuples indicating line from bodypart to bodypart, e.g. [('nose', 'tail_base')]\n",
    "    #   draws a line from the nose to the base of the tail.\n",
    "    #Also, to specify a midpoint, use a tuple in the tuple, e.g. [(('nose', 'tail_base'), 'paw_1')]\n",
    "    #   draws a line from the midpoint of 'nose' and 'tail_base' to a paw.\n",
    "\n",
    "    skeleton_lines = [('nose', 'paw1'), ('nose', 'paw2')]\n",
    "    #For each paw\n",
    "\n",
    "    #---------Plot 3D points with skeleton\n",
    "    scene_camera = dict(\n",
    "        up=dict(x=0, y=0, z=0),\n",
    "        center=dict(x=0, y=0, z=0),\n",
    "        eye=dict(x=0, y=-2, z=-2.5)\n",
    "    )\n",
    "    \n",
    "\n",
    "    fig = plot_cams_and_points(points_3d=slice_3d, scene_lims=scene_lims, point_size=5, scene_aspect='cube',                                scene_camera=scene_camera, show_plot=False, title=\"3D Points Through Time\", skeleton_bp=skeleton_bp,                                skeleton_lines=skeleton_lines)\n",
    "    fig.update_layout(showlegend=False)\n",
    "\n",
    "    fig.write_image(str(plot_dir / f\"3dpoints_{i}.png\"), width=width, height=height)\n",
    "\n",
    "    #--------------Now repeat, but include cameras in plot\n",
    "\n",
    "\n",
    "    fig = plot_cams_and_points(cam_group=cam_group, points_3d=slice_3d, point_size=5, scene_aspect='cube',                                scene_camera=scene_camera, show_plot=False, title=\"3D Points Through Time\", skeleton_bp=skeleton_bp,                                skeleton_lines=skeleton_lines)\n",
    "    fig.update_traces(textfont_size=1)\n",
    "    fig.update_layout(showlegend=False)\n",
    "    fig.write_image(str(plot_dir / f\"3dpoints_cams_{i}.png\"), width=width, height=height)\n",
    "\n"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Combine images\n",
    "from pathlib import Path\n",
    "from utils.utils_IO import read_image\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "combined_dir = Path('./combined/')\n",
    "combined_dir.mkdir(parents=True, exist_ok=True)\n",
    "for i in range(ind_start,ind_end):\n",
    "    im_int = str('%.5i' % i)\n",
    "    proj_im_path = plot_dir / f\"im{im_int}.png\"\n",
    "    proj_img = Image.open(proj_im_path)\n",
    "\n",
    "\n",
    "    point_im_path = plot_dir / f\"3dpoints_{i}.png\"\n",
    "    points_img = Image.open(point_im_path)\n",
    "\n",
    "    cam_im_path = plot_dir / f\"3dpoints_cams_{i}.png\"\n",
    "    cam_img = Image.open(cam_im_path)\n",
    "\n",
    "\n",
    "    width, height = proj_img.size\n",
    "    total_width = width * 3\n",
    "    total_height = height\n",
    "\n",
    "    new_im = Image.new('RGB', (total_width, total_height))\n",
    "\n",
    "    x_offset = 0\n",
    "    new_im.paste(proj_img, (0,0))\n",
    "    new_im.paste(points_img, (width,0))\n",
    "    new_im.paste(cam_img, (width * 2,0))\n",
    "\n",
    "    new_im.save(str(combined_dir / f\"combined_{i}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_video(image_dir=combined_dir, out_file='combined.mp4')"
   ]
  },
  {
   "source": [
    "# Epipolar Lines"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_start = 155\n",
    "ind_end = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "#Bundle adjustment code: https://scipy-cookbook.readthedocs.io/items/bundle_adjustment.html\n",
    "\n",
    "# Get rotation vector\n",
    "rot_vec_1 = R.from_rotvec(camera_1.get_rotation())\n",
    "R1 = rot_vec_1.as_matrix()\n",
    "print(\"R1: \", R1)\n",
    "#Get translation vector\n",
    "t1 = camera_1.get_translation()\n",
    "print('t1: ', t1)\n",
    "\n",
    "#Get intrinsic matrix\n",
    "K1 = camera_1.get_camera_matrix()\n",
    "\n",
    "# Get rotation vector\n",
    "rot_vec_2 = R.from_rotvec(camera_2.get_rotation())\n",
    "R2 = rot_vec_2.as_matrix()\n",
    "print(\"R2: \", R2)\n",
    "#Get translation vector\n",
    "t2 = camera_2.get_translation()\n",
    "print('t2: ', t2)\n",
    "\n",
    "#Get intrinsic matrix\n",
    "K2 = camera_2.get_camera_matrix()\n",
    "\n",
    "# --- Now compute relevant quantities for F estimation ------\n",
    "#Camera matrix basics: http://www.cs.cmu.edu/~16385/s17/Slides/11.1_Camera_matrix.pdf\n",
    "#Fundamental matrix computation: https://rb.gy/dd0nz2\n",
    "\n",
    "#Compute projection matrices\n",
    "P1 = np.matmul(K1, np.concatenate((R1, t1[:, np.newaxis]), axis=1))\n",
    "P2 = np.matmul(K2, np.concatenate((R2, t2[:, np.newaxis]), axis=1))\n",
    "\n",
    "#Get camera center (view 1)\n",
    "R1_inv = np.linalg.inv(R1) \n",
    "C = np.matmul(-R1_inv, t1)\n",
    "C = np.append(C, 1)\n",
    "\n",
    "F = np.matmul(skew(np.matmul(P2, C)), np.matmul(P2, np.linalg.pinv(P1)))\n",
    "print('F: ', F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_top = joined_list_2d[0]['x_coords'].ravel()[:,np.newaxis]\n",
    "y_top = joined_list_2d[0]['y_coords'].ravel()[:,np.newaxis]\n",
    "\n",
    "x_bot = joined_list_2d[1]['x_coords'].ravel()[:,np.newaxis]\n",
    "y_bot = joined_list_2d[1]['y_coords'].ravel()[:,np.newaxis]\n",
    "\n",
    "num_points = None\n",
    "if num_points is not None:\n",
    "    pts1 = np.concatenate((x_top, y_top), axis=-1)[:num_points, :]\n",
    "    pts2 = np.concatenate((x_bot, y_bot), axis=-1)[:num_points, :]\n",
    "else:\n",
    "    pts1 = np.concatenate((x_top, y_top), axis=-1)\n",
    "    pts2 = np.concatenate((x_bot, y_bot), axis=-1)\n",
    "\n",
    "F, mask = cv2.findFundamentalMat(pts1,pts2,cv2.FM_LMEDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epipolar_folder = './epipolar_lines/'\n",
    "if not os.path.exists(epipolar_folder):\n",
    "    os.makedirs(epipolar_folder)\n",
    "\n",
    "for i in range(ind_start,ind_end):\n",
    "    if i != 164:\n",
    "        continue\n",
    "\n",
    "    # load image\n",
    "    top_img = (read_image(path_images[0][i], flip=False) * 255).astype(np.uint8)\n",
    "    bottom_img = (read_image(path_images[1][i], flip=False) * 255).astype(np.uint8)\n",
    "\n",
    "    #Recall, indices 0 and 2 correspond to bottom image\n",
    "    x_t = joined_list_2d[0]['x_coords'][i][:,np.newaxis]\n",
    "    y_t = joined_list_2d[0]['y_coords'][i][:,np.newaxis]\n",
    "\n",
    "    x_b = joined_list_2d[1]['x_coords'][i][:,np.newaxis]\n",
    "    y_b = joined_list_2d[1]['y_coords'][i][:,np.newaxis]\n",
    "\n",
    "    points_top = np.concatenate((x_t,y_t), axis=1)\n",
    "    points_bot = np.concatenate((x_b,y_b), axis=1)\n",
    "\n",
    "    \n",
    "    #Get rid of nans\n",
    "    points_bot = points_bot.astype(np.int32)\n",
    "    points_bot = points_bot[~np.isnan(points_bot).any(axis=1)]\n",
    "\n",
    "    points_top = points_top.astype(np.int32)\n",
    "    points_top = points_top[~np.isnan(points_top).any(axis=1)]\n",
    "\n",
    "    top_img_with_points = draw_circles(top_img, points_top)\n",
    "    bot_img_with_points = draw_circles(bottom_img, points_bot)\n",
    "    #cv2.imwrite('epipolar_lines/top_image_points.jpg', top_img_with_points)\n",
    "    #cv2.imwrite('epipolar_lines/bot_image_points.jpg', bot_img_with_points)\n",
    "\n",
    "    #Homogenize points\n",
    "    ones = np.ones(points_top.shape[0])[:,np.newaxis]\n",
    "    points_top_homog = np.concatenate((points_top, ones), axis=-1)\n",
    "    points_bot_homog = np.concatenate((points_bot, ones), axis=-1)\n",
    "    \n",
    "    aug_F = np.tile(F, (points_top_homog.shape[0], 1, 1))\n",
    "    lines_bot = np.squeeze(np.matmul(aug_F, points_top_homog[:,:,np.newaxis]))\n",
    "    #This^ gives us lines as vectors [a,b,c] --> ax + by + c = 0\n",
    "\n",
    "    for line_vec in lines_bot:\n",
    "        #Get x and y intercepts (on image) to plot\n",
    "        #y = 0: x = -c/a\n",
    "        x_intercept = int(-line_vec[2] / line_vec[0])\n",
    "        #x = 0: y = -c/b\n",
    "        y_intercept = int(-line_vec[2] / line_vec[1])\n",
    "        bottom_img = drawLine(bottom_img, x_intercept, 0, 0, y_intercept)\n",
    "        #bottom_img = cv2.line(bottom_img, (x_intercept, 0), (0, y_intercept), (255, 255, 255), thickness=1)\n",
    "\n",
    "    final_img = cv2.vconcat([top_img, bottom_img])\n",
    "    cv2.imwrite(f'epipolar_lines/{i}.jpg', final_img)\n",
    "    if i == 164:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_video(image_dir=epipolar_folder, out_file=\"epipolar_video.mp4\")"
   ]
  },
  {
   "source": [
    "# Undistorting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python_defaultSpec_1601942587919",
   "display_name": "Python 3.7.7 64-bit ('bundle-adjust': conda)",
   "metadata": {
    "interpreter": {
     "hash": "1e40af101b7b669b5075d06212a9bc21d31e72e4401f57802a1c8d1908bf11a4"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}