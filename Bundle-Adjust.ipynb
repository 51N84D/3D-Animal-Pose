{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import urllib\n",
    "import bz2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import plotly.graph_objs as go\n",
    "import os\n",
    "from utils.utils_IO import ordered_arr_3d_to_dict, refill_nan_array, arr_2d_to_list_of_dicts, read_image, make_image_array, revert_ordered_arr_2d_to_dict, save_object, write_video\n",
    "from utils.utils_plotting import plot_image_labels, plot_3d_points, vector_plot, draw_circles, slope, drawLine, skew, plot_cams_and_points\n",
    "from utils.utils_BA import fun, bundle_adjustment_sparsity, project\n",
    "from anipose_BA import CameraGroup, Camera\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOP_IMG_HEIGHT=168\n",
    "BOT_IMG_HEIGHT=238\n",
    "IMG_WIDTH= 396\n",
    "P_X_1 = P_X_1 = IMG_WIDTH // 2\n",
    "P_Y_2 = BOT_IMG_HEIGHT // 2\n",
    "P_Y_1 = TOP_IMG_HEIGHT // 2\n",
    "#(Camera, Coordinates)\n",
    "#OFFSET = np.asarray([[P_Y_1, P_X_1], [P_Y_2, P_X_1]])\n",
    "OFFSET = np.asarray([[P_X_1, P_Y_1], [P_X_1, P_Y_2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_folder = './mouseRunningData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DLC_dframe = pd.read_csv(data_folder + '/CollectedData_.csv', \n",
    "                         header = [1,2]) \n",
    "# header = [1,2] is important. Provides a hierarchical data frame\n",
    "DLC_dframe.head() # inspect\n",
    "#DLC_dframe['paw1LH_top','x'] # that's how you index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the bodyparts, coords entries.\n",
    "DLC_dframe = DLC_dframe.rename(columns = { \\\n",
    "    \"bodyparts\":\"img_name\", \"coords\":\"img_name\" })\n",
    "DLC_dframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bodyparts = list(DLC_dframe.columns.levels[0][1:]) # [1:] to remove img name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def sorted_nicely( l ): \n",
    "    \"\"\" Sort the given iterable in the way that humans expect.\"\"\" \n",
    "    convert = lambda text: int(text) if text.isdigit() else text \n",
    "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
    "    return sorted(l, key = alphanum_key)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path_images = data_folder + \\\n",
    "                '/' + \\\n",
    "                DLC_dframe[\"img_name\", \"img_name\"]\\\n",
    "                .to_numpy()\n",
    "\n",
    "\n",
    "path_images_1 = sorted_nicely(os.listdir(Path(data_folder) / 'camera1Images/'))\n",
    "path_images_1 = [str(Path(data_folder).resolve() / Path('camera1Images/') / i) for i in path_images_1]\n",
    "\n",
    "path_images_2 = sorted_nicely(os.listdir(Path(data_folder) / 'camera2Images/'))\n",
    "path_images_2 = [str(Path(data_folder).resolve() / Path('camera2Images/') / i) for i in path_images_2]\n",
    "\n",
    "path_images = [path_images_1, path_images_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pick either all body parts or part of them\n",
    "#bp2plot = ['nose_bot', 'nose_top', 'tailBase_bot', 'tailBase_top']\n",
    "bp2plot = bodyparts\n",
    "pose_2D_dict = {}\n",
    "pose_2D_dict[\"x_coords\"] = DLC_dframe.loc[: , (bp2plot , 'x')].to_numpy() # DLC_dframe[bp2plot]\n",
    "pose_2D_dict[\"y_coords\"] = DLC_dframe.loc[: , (bp2plot , 'y')].to_numpy() # DLC_dframe[bp2plot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# using https://stackoverflow.com/questions/12897374/get-unique-values-from-a-list-in-python\n",
    "'''just these body parts that are seen from both views.'''\n",
    "bp2plot = bodyparts\n",
    "bp_short = []\n",
    "for i in range(len(bp2plot)):\n",
    "    if bp2plot[i][:3] != 'obs': # not plotting the obstacle\n",
    "        bp_short.append(bp2plot[i][:-4]) # last four chars (_top/_bot)\n",
    "\n",
    "short_list = list(set(bp_short)) # set returns unique elements in list\n",
    "short_list_bot = []\n",
    "short_list_top = []\n",
    "for i in short_list:\n",
    "    short_list_bot.append(i + '_bot')\n",
    "    short_list_top.append(i + '_top')\n",
    "short_list_top.sort()\n",
    "short_list_bot.sort()\n",
    "tuple_x= (short_list_top, 'x')\n",
    "tuple_y= (short_list_top, 'y')\n",
    "tuple_z = (short_list_bot, 'y') #Remember to negate (right-hand-rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing / Re-mapping coordinates for bottom image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat bottom image separately\n",
    "# Remap y-values for bottom image\n",
    "# NOTE: THIS IS ONLY BECAUSE'S THE 2 CAMERA VIEWS IN RICK'S DATA\n",
    "#   COME AS A SINGLE IAMGE\n",
    "#   SO, WE NEED TO SCALE THE POINTS ACCORDINGLY\n",
    "DLC_dframe.loc[: , tuple_z] -= TOP_IMG_HEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract 3d from rick\n",
    "pose_dict_3d = {}\n",
    "pose_dict_3d[\"x_coords\"] = DLC_dframe.loc[: , \\\n",
    "                            tuple_x].to_numpy() # DLC_dframe[bp2plot]\n",
    "pose_dict_3d[\"y_coords\"] = DLC_dframe.loc[: , \\\n",
    "                            tuple_y].to_numpy() #/ DLC_dframe[bp2plot]\n",
    "\n",
    "pose_dict_3d[\"z_coords\"] = - DLC_dframe.loc[: , \\\n",
    "                           tuple_z].to_numpy()  # DLC_dframe[bp2plot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transform to BA format\n",
    "pts_array_3d = np.hstack([pose_dict_3d[\"x_coords\"].flatten().reshape(-1,1), \n",
    "           pose_dict_3d[\"y_coords\"].flatten().reshape(-1,1),\n",
    "                         pose_dict_3d[\"z_coords\"].flatten().reshape(-1,1)])\n",
    "\n",
    "print('original number of unique pts was %d' % pts_array_3d.shape[0])\n",
    "nan_pts_3d = np.isnan(pts_array_3d).any(axis=1) # remove 3d points here and in each view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# removing_nans\n",
    "print('excluding %d tracked points!' % np.sum(nan_pts_3d==True)) # number of excluded 3d points.\n",
    "pts_array_3d_clean = pts_array_3d[~nan_pts_3d, :]\n",
    "pts_all_flat = np.arange(pts_array_3d.shape[0])\n",
    "clean_point_indices = pts_all_flat[~nan_pts_3d]\n",
    "\n",
    "#(clean_point_indices == np.where(~nan_pts_3d)).all() # True\n",
    "info_dict = {}\n",
    "info_dict[\"num_frames\"] = DLC_dframe.shape[0]\n",
    "info_dict[\"num_analyzed_body_parts\"] = len(short_list)\n",
    "info_dict[\"num_cameras\"] = 2\n",
    "info_dict[\"num_points_all\"] = pts_array_3d.shape[0]\n",
    "info_dict[\"clean_point_indices\"] = pts_all_flat[~nan_pts_3d]\n",
    "assert(info_dict[\"num_points_all\"] == \n",
    "           info_dict[\"num_frames\"]*info_dict[\"num_analyzed_body_parts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract params for BA. assuming all points are visible from the two cameras (even if nans)\n",
    "# only body parts that are visible in both views\n",
    "tuple_x_bot = (short_list_bot, 'x')\n",
    "tuple_y_bot = (short_list_bot, 'y')\n",
    "tuple_x_top = (short_list_top, 'x')\n",
    "tuple_y_top = (short_list_top, 'y')\n",
    "\n",
    "# hstack x,y\n",
    "pts_array_2d_bot_full = np.hstack([DLC_dframe.loc[: , \\\n",
    "        tuple_x_bot].to_numpy().flatten().reshape(-1,1),\n",
    "                             DLC_dframe.loc[: , \\\n",
    "        tuple_y_bot].to_numpy().flatten().reshape(-1,1)])\n",
    "\n",
    "print(pts_array_2d_bot_full.shape)\n",
    "\n",
    "# remove nan_pts_3d rows\n",
    "pts_array_2d_bot = pts_array_2d_bot_full[~nan_pts_3d, :]\n",
    "\n",
    "# hstack x,y, and remove nan_pts_3d rows.\n",
    "pts_array_2d_top_full = np.hstack([DLC_dframe.loc[: , \\\n",
    "        tuple_x_top].to_numpy().flatten().reshape(-1,1),\n",
    "                             DLC_dframe.loc[: , \\\n",
    "        tuple_y_top].to_numpy().flatten().reshape(-1,1)])\n",
    "\n",
    "pts_array_2d_top = pts_array_2d_top_full[~nan_pts_3d, :]\n",
    "\n",
    "print(tuple_x_top)\n",
    "\n",
    "print('shape of each 2d pt array is %s and %s' %(\n",
    "    str(pts_array_2d_bot.shape),\n",
    "    str(pts_array_2d_top.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_array_2d = np.concatenate((pts_array_2d_top[np.newaxis,:,:], pts_array_2d_bot[np.newaxis,:,:]), axis=0)\n",
    "pts_array_2d_og = np.reshape(pts_array_2d, (pts_array_2d.shape[0] * pts_array_2d.shape[1], -1))\n",
    "\n",
    "array_2d_orig = refill_nan_array(pts_array_2d_og, \n",
    "                              info_dict, \n",
    "                               dimension = '2d')\n",
    "                               \n",
    "pose_list_2d_orig = arr_2d_to_list_of_dicts(array_2d_orig,\n",
    "                                              info_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements for Bundle Adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "`P_{X,Y}_{TOP,BOT}`: (int) - {width / 2, height / 2} for camera {1,2}\n",
    "\n",
    "-->For setting the offset terms in the camera matrix to the center of the image plane\n",
    "\n",
    "\n",
    "`pts_array_2d`: (np.array) - Array of shape (num_cameras, num_points, 2) containing set of 2d points for each camera. This should be after cleaning NaNs i.e. removing rows with NaNs\n",
    "\n",
    "`info_dict`: Dictionary with keys {'num_frames', 'num_analyzed_body_parts', 'num_cameras', 'num_points_all', 'clean_point_indices'}\n",
    "\n",
    "--> 'num_frames' is the number of frames in the video\n",
    "\n",
    "--> 'num_analyzed_body_parts' is the number of body parts / joints being modeled (i.e. one per keypoint)\n",
    "\n",
    "--> 'num_cameras' is the number of cameras. In our case, it is 2\n",
    "\n",
    "--> 'num_points_all' is the original number of points (including NaNs)\n",
    "\n",
    "--> 'clean_point_indices' is a list of indices (with length = num_points in `pts_array_2d`) pointing to the clean (non-NaN) entries in the original data\n",
    "\n",
    "`path_images`: (list) - List of sublists. Each sublist (one per camera / view) contains absolute paths to image frames. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "def save_object(obj, filename, objects_dir='./rick_data_objects/'):\n",
    "    with open(Path(objects_dir) / filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_object(filename, objects_dir='./rick_data_objects/'):\n",
    "    obj = None\n",
    "    with open(Path(objects_dir) / filename, 'rb') as input:\n",
    "        obj = pickle.load(input)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "save_object(info_dict, 'info_dict.pkl')\n",
    "save_object(pts_array_2d, 'pts_array_2d.pkl')\n",
    "offsets = [P_X_1, P_Y_1, P_X_1, P_Y_2]\n",
    "save_object(offsets, 'offsets.pkl')\n",
    "save_object(path_images, 'path_images.pkl')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#Load\n",
    "info_dict = load_object('info_dict.pkl')\n",
    "pts_array_2d = load_object('pts_array_2d.pkl')\n",
    "offsets = load_object('offsets.pkl')\n",
    "path_images = load_object('path_images.pkl')\n",
    "[P_X_1, P_Y_1, P_X_1, P_Y_2] = offsets\n",
    "IMG_WIDTH = P_X_1 * 2\n",
    "TOP_IMG_HEIGHT = P_Y_1 * 2\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bundle Adjust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--------CAMERA 1------------\n",
    "#Initialize camera 1\n",
    "camera_1 = Camera(rvec=[0,0,0], tvec=[0,0,0])\n",
    "#Set offset\n",
    "camera_1.set_size((P_X_1, P_Y_1))\n",
    "\n",
    "cam1_init_params = np.abs(np.random.rand(8))\n",
    "#Set rotations [0:3] and translation [3:6] to 0\n",
    "cam1_init_params[0:6] = 0\n",
    "#Initialize focal length to image width\n",
    "cam1_init_params[6] = P_X_1 * 2\n",
    "#Initialize distortion to 0\n",
    "cam1_init_params[7] = 0.0 \n",
    "#Set parameters\n",
    "camera_1.set_params(cam1_init_params)\n",
    "\n",
    "#--------CAMERA 2------------\n",
    "#Set rotation vector w.r.t. camera 1\n",
    "rvec2 = np.pi/2 * np.array([1, 0, 0])\n",
    "#Set translation vector w.r.t. camera 1\\\n",
    "tvec2 = [0, 1, 1]\n",
    "#Initialize camera 2\n",
    "camera_2 = Camera(rvec=rvec2, tvec=tvec2)\n",
    "#Set offset \n",
    "camera_1.set_size((P_X_1, P_Y_2))\n",
    "\n",
    "cam2_init_params = np.abs(np.random.rand(8))\n",
    "cam2_init_params[0:3] = rvec2\n",
    "cam2_init_params[3:6] = tvec2\n",
    "cam2_init_params[6] = P_X_1 * 2\n",
    "cam2_init_params[7] = 0.0\n",
    "camera_2.set_params(cam2_init_params)\n",
    "\n",
    "#Group cameras\n",
    "cam_group = CameraGroup(cameras=[camera_1, camera_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Get error before Bundle Adjustment by triangulating using the initial parameters:\n",
    "f0, points_3d_init = cam_group.get_initial_error(pts_array_2d)\n",
    "print(points_3d_init.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plot_cams_and_points(cam_group=cam_group, points_3d=points_3d_init, title=\"3D Points Initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Run Bundle Adjustment\n",
    "res, points_3d = cam_group.bundle_adjust(pts_array_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_cams_and_points(cam_group=cam_group, points_3d=points_3d, title=\"3D Points Bundle Adjusted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Get projected points\n",
    "points_proj_1 = camera_1.project(points_3d, ).squeeze()\n",
    "points_proj_2 = camera_2.project(points_3d).squeeze()\n",
    "points_proj = np.concatenate((points_proj_1, points_proj_2), axis=0)\n",
    "print('f_1: ', camera_1.get_focal_length())\n",
    "print('f_2: ', camera_2.get_focal_length())\n",
    "print('dist_1: ', camera_1.get_distortions())\n",
    "print('dist_2: ', camera_2.get_distortions())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_folder = 'rick_plots'\n",
    "if not os.path.exists(plot_folder):\n",
    "    os.makedirs(plot_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(f0, label = 'pre optim, random init')\n",
    "plt.plot(res.fun, label = 'after optim')\n",
    "plt.legend()\n",
    "plt.ylabel('coordinate-wise signed reproj-error')\n",
    "plt.title('reprojection error before and after optim')\n",
    "plt.savefig(os.path.join(plot_folder,'reproj-err-per-frame-initdlc3d.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now we first refill the full sized containers, then revert to dicts.\n",
    "\n",
    "# do the pts_array_3d_clean\n",
    "array_3d_back = refill_nan_array(points_3d, \n",
    "                               info_dict, \n",
    "                               dimension = '3d')\n",
    "pose_dict_3d_refill = ordered_arr_3d_to_dict(array_3d_back, info_dict)\n",
    "\n",
    "# pts_3d_BA\n",
    "BA_array_3d_back = refill_nan_array(points_3d, \n",
    "                               info_dict, \n",
    "                               dimension = '3d')\n",
    "BA_dict = ordered_arr_3d_to_dict(BA_array_3d_back, info_dict)\n",
    "\n",
    "# pts_2d_orig\n",
    "pts_array_2d_og = np.reshape(pts_array_2d, (pts_array_2d.shape[0] * pts_array_2d.shape[1], -1))\n",
    "array_2d_orig = refill_nan_array(pts_array_2d_og, \n",
    "                              info_dict, \n",
    "                               dimension = '2d')\n",
    "pose_list_2d_orig = arr_2d_to_list_of_dicts(array_2d_orig,\n",
    "                                              info_dict)\n",
    "                                              \n",
    "# pts_2d_reproj\n",
    "array_2d_reproj_back = refill_nan_array(points_proj, \n",
    "                              info_dict, \n",
    "                               dimension = '2d')\n",
    "pose_list_2d_reproj = arr_2d_to_list_of_dicts(array_2d_reproj_back,\n",
    "                                              info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joined_list_2d = pose_list_2d_orig + pose_list_2d_reproj\n",
    "joined_list_3d = []\n",
    "joined_list_3d.append(pose_dict_3d_refill)\n",
    "joined_list_3d.append(BA_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Red = ground truth, blue = proj\n",
    "color_list_2d = ['red', 'red', 'blue', 'blue']\n",
    "color_list_3d = ['red', 'blue']\n",
    "# set limits to be the maximum of the two plots\n",
    "# we are padding the limits of the axis since some points lie at the border.\n",
    "pad = 1\n",
    "lims = {}\n",
    "x_min = np.nanmin(BA_dict['x_coords'])\n",
    "x_max = np.nanmax(BA_dict['x_coords'])\n",
    "y_min = np.nanmin(BA_dict['y_coords'])\n",
    "y_max = np.nanmax(BA_dict['y_coords'])\n",
    "z_min = np.nanmin(BA_dict['z_coords'])\n",
    "z_max = np.nanmax(BA_dict['z_coords'])\n",
    "lims['x'] = [x_min, x_max]\n",
    "lims['y'] = [y_min, y_max]\n",
    "lims['z'] = [z_min, z_max]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_start = 155\n",
    "ind_end = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### 3d plot\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import mpl_toolkits.mplot3d.axes3d as p3\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(constrained_layout=True, figsize = (12,6))\n",
    "gs = GridSpec(2, 2, figure=fig)\n",
    "ax1 = fig.add_subplot(gs[:2, 0])\n",
    "ax2 = fig.add_subplot(gs[:2, 1], projection = '3d') # https://matplotlib.org/3.1.1/gallery/mplot3d/subplot3d.html\n",
    "image_folder = 'images_test'\n",
    "if not os.path.exists(image_folder):\n",
    "    os.makedirs(image_folder)\n",
    "\n",
    "ax2.view_init(elev=0, azim=90) # see https://stackoverflow.com/questions/12904912/how-to-set-camera-position-for-3d-plots-using-python-matplotlib\n",
    "\n",
    "#FRONT RIGHT PAW\n",
    "for i in range(ind_start,ind_end):\n",
    "    # clear both ax1 and ax2\n",
    "    ax1.cla()\n",
    "    ax2.cla()   \n",
    "    # load image\n",
    "    img_1 = read_image(path_images[0][i], flip=False)\n",
    "    img_2 = read_image(path_images[1][i], flip=False)\n",
    "    img = np.concatenate((img_1, img_2), axis=0)\n",
    "    plot_image_labels(img,\\\n",
    "                        joined_list_2d,\n",
    "                        i,\n",
    "                        color_list_2d,\n",
    "                        ax = ax1, top_img_height=TOP_IMG_HEIGHT)\n",
    "    \n",
    "    ax2.azim += 1\n",
    "    plot_3d_points(joined_list_3d,\n",
    "                   lims,\n",
    "                   i,\n",
    "                   color_list_3d,\n",
    "                   ax=ax2)\n",
    "    im_int = str('%.5i' % i)\n",
    "    plt.savefig(image_folder + '/' + 'im' + im_int + '.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_video(image_dir='./images_test/', out_file='reconstruction.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Bundle Adjusted Through Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get axis lims\n",
    "x_min = np.nanmin(BA_dict['x_coords'])\n",
    "x_max = np.nanmax(BA_dict['x_coords'])\n",
    "y_min = np.nanmin(BA_dict['y_coords'])\n",
    "y_max = np.nanmax(BA_dict['y_coords'])\n",
    "z_min = np.nanmin(BA_dict['z_coords'])\n",
    "z_max = np.nanmax(BA_dict['z_coords'])\n",
    "scene_lims = [[x_min,x_max], [y_min,y_max], [z_min,z_max]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_dir = Path('./3d_point_plots/')\n",
    "plot_dir.mkdir(exist_ok=True, parents=True)\n",
    "for i in range(ind_start, ind_end):\n",
    "    slice_3d = np.asarray([BA_dict['x_coords'][i], BA_dict['y_coords'][i],BA_dict['z_coords'][i]]).transpose()\n",
    "    fig = plot_cams_and_points(points_3d=slice_3d, scene_lims=None, point_size=5, scene_aspect='cube', show_plot=False, title=\"3D Points Through Time\")\n",
    "    fig.write_image(str(plot_dir / f\"points_{i}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_video(image_dir=plot_dir, out_file=\"points_through_time.mp4\")"
   ]
  },
  {
   "source": [
    "# Plot Skeleton"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### 3d plot\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "%matplotlib inline\n",
    "plot_dir = Path('./3d_point_plots/')\n",
    "\n",
    "fig = plt.figure(constrained_layout=True, figsize = (12,6))\n",
    "gs = GridSpec(1, 1, figure=fig)\n",
    "ax1 = fig.add_subplot(gs[:2, 0])\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)\n",
    "\n",
    "\n",
    "for i in range(ind_start,ind_end):\n",
    "    # clear both ax1 and ax2\n",
    "    ax1.cla()\n",
    "    # load image\n",
    "    img_1 = read_image(path_images[0][i], flip=False)\n",
    "    img_2 = read_image(path_images[1][i], flip=False)\n",
    "    img = np.concatenate((img_1, img_2), axis=0)\n",
    "\n",
    "    plot_image_labels(img,\\\n",
    "                        joined_list_2d,\n",
    "                        i,\n",
    "                        color_list_2d,\n",
    "                        ax = ax1, top_img_height=TOP_IMG_HEIGHT)\n",
    "\n",
    "    im_int = str('%.5i' % i)\n",
    "    plt.savefig(str(plot_dir / ('im' + im_int + '.png')),bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#['nose', 'paw1LH', 'paw2LF', 'paw3RF', 'paw4RH', 'tailBase', 'tailMid']\n",
    "#0: nose\n",
    "#1: left front paw\n",
    "#2: left back paw\n",
    "#3: right back paw\n",
    "#4: right front\n",
    "#5: tail base\n",
    "#6: tail mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plot skeleton\n",
    "from PIL import Image\n",
    "\n",
    "for i in range(ind_start, ind_end):\n",
    "    im_int = str('%.5i' % i)\n",
    "    proj_im_path = plot_dir / f\"im{im_int}.png\"\n",
    "    proj_img = Image.open(proj_im_path)\n",
    "    width, height = proj_img.size\n",
    "\n",
    "    slice_3d = np.asarray([BA_dict['x_coords'][i], BA_dict['y_coords'][i],BA_dict['z_coords'][i]]).transpose()\n",
    "    \n",
    "    #Add coordinates of each bodypart to dict\n",
    "    skeleton_bp = {}\n",
    "    skeleton_bp['nose'] = (BA_dict['x_coords'][i][0], BA_dict['y_coords'][i][0], BA_dict['z_coords'][i][0])\n",
    "    skeleton_bp['tail_base'] = (BA_dict['x_coords'][i][5], BA_dict['y_coords'][i][5], BA_dict['z_coords'][i][5])\n",
    "    skeleton_bp['tail_mid'] = (BA_dict['x_coords'][i][6], BA_dict['y_coords'][i][6], BA_dict['z_coords'][i][6])\n",
    "    #Draw vector from tail_base to tail_mid\n",
    "    for index in range(1,5):\n",
    "        skeleton_bp[f\"paw_{index}\"] = (BA_dict['x_coords'][i][index], BA_dict['y_coords'][i][index], BA_dict['z_coords'][i][index])\n",
    "\n",
    "    #Now, define lines:\n",
    "    #List of tuples indicating line from bodypart to bodypart, e.g. [('nose', 'tail_base')]\n",
    "    #   draws a line from the nose to the base of the tail.\n",
    "    #Also, to specify a midpoint, use a tuple in the tuple, e.g. [(('nose', 'tail_base'), 'paw_1')]\n",
    "    #   draws a line from the midpoint of 'nose' and 'tail_base' to a paw.\n",
    "\n",
    "    skeleton_lines = [('nose', 'tail_base'), ('tail_base', 'tail_mid')]\n",
    "    #For each paw\n",
    "    for index in range(1,5):\n",
    "        #Draw a line from the midpoint of nose and tail_base to each paw\n",
    "        skeleton_lines.append((('nose', 'tail_base'), f'paw_{index}'))\n",
    "\n",
    "\n",
    "    #---------Plot 3D points with skeleton\n",
    "    scene_camera = dict(\n",
    "        up=dict(x=0, y=0, z=0),\n",
    "        center=dict(x=0, y=0, z=0),\n",
    "        eye=dict(x=0, y=-1, z=-2.5)\n",
    "    )\n",
    "\n",
    "    fig = plot_cams_and_points(points_3d=slice_3d, scene_lims=scene_lims, point_size=5, scene_aspect='cube',                                scene_camera=scene_camera, show_plot=False, title=\"3D Points Through Time\", skeleton_bp=skeleton_bp,                                skeleton_lines=skeleton_lines)\n",
    "\n",
    "    fig.write_image(str(plot_dir / f\"3dpoints_{i}.png\"), width=width, height=height)\n",
    "\n",
    "    #--------------Now repeat, but include cameras in plot\n",
    "\n",
    "\n",
    "    fig = plot_cams_and_points(cam_group=cam_group, points_3d=slice_3d, point_size=5, scene_aspect='cube',                                scene_camera=scene_camera, show_plot=False, title=\"3D Points Through Time\", skeleton_bp=skeleton_bp,                                skeleton_lines=skeleton_lines)\n",
    "    fig.update_traces(textfont_size=1)\n",
    "    fig.write_image(str(plot_dir / f\"3dpoints_cams_{i}.png\"), width=width, height=height)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Combine images\n",
    "from pathlib import Path\n",
    "from utils.utils_IO import read_image\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "combined_dir = Path('./combined/')\n",
    "combined_dir.mkdir(parents=True, exist_ok=True)\n",
    "for i in range(ind_start,ind_end):\n",
    "    im_int = str('%.5i' % i)\n",
    "    proj_im_path = plot_dir / f\"im{im_int}.png\"\n",
    "    proj_img = Image.open(proj_im_path)\n",
    "\n",
    "\n",
    "    point_im_path = plot_dir / f\"3dpoints_{i}.png\"\n",
    "    points_img = Image.open(point_im_path)\n",
    "\n",
    "    cam_im_path = plot_dir / f\"3dpoints_cams_{i}.png\"\n",
    "    cam_img = Image.open(cam_im_path)\n",
    "\n",
    "\n",
    "    width, height = proj_img.size\n",
    "    total_width = width * 3\n",
    "    total_height = height\n",
    "\n",
    "    new_im = Image.new('RGB', (total_width, total_height))\n",
    "\n",
    "    x_offset = 0\n",
    "    new_im.paste(proj_img, (0,0))\n",
    "    new_im.paste(points_img, (width,0))\n",
    "    new_im.paste(cam_img, (width * 2,0))\n",
    "\n",
    "    new_im.save(str(combined_dir / f\"combined_{i}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_video(image_dir=combined_dir, out_file='combined.mp4')"
   ]
  },
  {
   "source": [
    "# Epipolar Lines"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_start = 155\n",
    "ind_end = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "#Bundle adjustment code: https://scipy-cookbook.readthedocs.io/items/bundle_adjustment.html\n",
    "\n",
    "# Get rotation vector\n",
    "rot_vec_1 = R.from_rotvec(camera_1.get_rotation())\n",
    "R1 = rot_vec_1.as_matrix()\n",
    "print(\"R1: \", R1)\n",
    "#Get translation vector\n",
    "t1 = camera_1.get_translation()\n",
    "print('t1: ', t1)\n",
    "\n",
    "#Get intrinsic matrix\n",
    "K1 = camera_1.get_camera_matrix()\n",
    "\n",
    "# Get rotation vector\n",
    "rot_vec_2 = R.from_rotvec(camera_2.get_rotation())\n",
    "R2 = rot_vec_2.as_matrix()\n",
    "print(\"R2: \", R2)\n",
    "#Get translation vector\n",
    "t2 = camera_2.get_translation()\n",
    "print('t2: ', t2)\n",
    "\n",
    "#Get intrinsic matrix\n",
    "K2 = camera_2.get_camera_matrix()\n",
    "\n",
    "# --- Now compute relevant quantities for F estimation ------\n",
    "#Camera matrix basics: http://www.cs.cmu.edu/~16385/s17/Slides/11.1_Camera_matrix.pdf\n",
    "#Fundamental matrix computation: https://rb.gy/dd0nz2\n",
    "\n",
    "#Compute projection matrices\n",
    "P1 = np.matmul(K1, np.concatenate((R1, t1[:, np.newaxis]), axis=1))\n",
    "P2 = np.matmul(K2, np.concatenate((R2, t2[:, np.newaxis]), axis=1))\n",
    "\n",
    "#Get camera center (view 1)\n",
    "R1_inv = np.linalg.inv(R1) \n",
    "C = np.matmul(-R1_inv, t1)\n",
    "C = np.append(C, 1)\n",
    "\n",
    "F = np.matmul(skew(np.matmul(P2, C)), np.matmul(P2, np.linalg.pinv(P1)))\n",
    "print('F: ', F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_top = joined_list_2d[0]['x_coords'].ravel()[:,np.newaxis]\n",
    "y_top = joined_list_2d[0]['y_coords'].ravel()[:,np.newaxis]\n",
    "\n",
    "x_bot = joined_list_2d[1]['x_coords'].ravel()[:,np.newaxis]\n",
    "y_bot = joined_list_2d[1]['y_coords'].ravel()[:,np.newaxis]\n",
    "\n",
    "num_points = 20\n",
    "pts1 = np.concatenate((x_top, y_top), axis=-1)[:num_points, :]\n",
    "pts2 = np.concatenate((x_bot, y_bot), axis=-1)[:num_points, :]\n",
    "\n",
    "F, mask = cv2.findFundamentalMat(pts1,pts2,cv2.FM_LMEDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epipolar_folder = './epipolar_lines/'\n",
    "if not os.path.exists(epipolar_folder):\n",
    "    os.makedirs(epipolar_folder)\n",
    "\n",
    "for i in range(ind_start,ind_end):\n",
    "    # load image\n",
    "    top_img = (read_image(path_images[0][i], flip=False) * 255).astype(np.uint8)\n",
    "    bottom_img = (read_image(path_images[1][i], flip=False) * 255).astype(np.uint8)\n",
    "\n",
    "    #Recall, indices 0 and 2 correspond to bottom image\n",
    "    x_t = joined_list_2d[0]['x_coords'][i][:,np.newaxis]\n",
    "    y_t = joined_list_2d[0]['y_coords'][i][:,np.newaxis]\n",
    "\n",
    "    x_b = joined_list_2d[1]['x_coords'][i][:,np.newaxis]\n",
    "    y_b = joined_list_2d[1]['y_coords'][i][:,np.newaxis]\n",
    "\n",
    "    points_top = np.concatenate((x_t,y_t), axis=1)\n",
    "    points_bot = np.concatenate((x_b,y_b), axis=1)\n",
    "\n",
    "    \n",
    "    #Get rid of nans\n",
    "    points_bot = points_bot.astype(np.int32)\n",
    "    points_bot = points_bot[~np.isnan(points_bot).any(axis=1)]\n",
    "\n",
    "    points_top = points_top.astype(np.int32)\n",
    "    points_top = points_top[~np.isnan(points_top).any(axis=1)]\n",
    "\n",
    "\n",
    "    top_img_with_points = draw_circles(top_img, points_top)\n",
    "    bot_img_with_points = draw_circles(bottom_img, points_bot)\n",
    "    #cv2.imwrite('epipolar_lines/top_image_points.jpg', top_img_with_points)\n",
    "    #cv2.imwrite('epipolar_lines/bot_image_points.jpg', bot_img_with_points)\n",
    "\n",
    "    #Homogenize points\n",
    "    ones = np.ones(points_top.shape[0])[:,np.newaxis]\n",
    "    points_top_homog = np.concatenate((points_top, ones), axis=-1)\n",
    "    points_bot_homog = np.concatenate((points_bot, ones), axis=-1)\n",
    "    \n",
    "    aug_F = np.tile(F, (points_top_homog.shape[0], 1, 1))\n",
    "    lines_bot = np.squeeze(np.matmul(aug_F, points_top_homog[:,:,np.newaxis]))\n",
    "    #This^ gives us lines as vectors [a,b,c] --> ax + by + c = 0\n",
    "\n",
    "    for line_vec in lines_bot:\n",
    "        #Get x and y intercepts (on image) to plot\n",
    "        #y = 0: x = -c/a\n",
    "        x_intercept = int(-line_vec[2] / line_vec[0])\n",
    "        #x = 0: y = -c/b\n",
    "        y_intercept = int(-line_vec[2] / line_vec[1])\n",
    "        bottom_img = drawLine(bottom_img, x_intercept, 0, 0, y_intercept)\n",
    "        #bottom_img = cv2.line(bottom_img, (x_intercept, 0), (0, y_intercept), (255, 255, 255), thickness=1)\n",
    "\n",
    "    final_img = cv2.vconcat([top_img, bottom_img])\n",
    "    cv2.imwrite(f'epipolar_lines/{i}.jpg', final_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_video(image_dir=epipolar_folder, out_file=\"epipolar_video.mp4\")"
   ]
  },
  {
   "source": [
    "# Undistorting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python_defaultSpec_1601138716649",
   "display_name": "Python 3.7.7 64-bit ('bundle-adjust': conda)",
   "metadata": {
    "interpreter": {
     "hash": "32520c86abf82c892aed4d5a41ce6e3cb51d4685bf7efbb4354347400de401e4"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}