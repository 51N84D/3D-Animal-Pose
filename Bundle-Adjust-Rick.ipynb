{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import urllib\n",
    "import bz2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import utils_IO as utils_IO\n",
    "import utils_BA as utils_BA\n",
    "import utils_plotting as utils_plotting\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered_arr_3d_to_dict(pts_array_3d, info_dict):\n",
    "    '''assuming you used np.flatten(). to create the 3d points.\n",
    "    and assuming that the pts array is full size, including nans.'''\n",
    "    pose_dict = {}\n",
    "    pose_dict[\"x_coords\"] = pts_array_3d[:,0].reshape(\n",
    "            info_dict[\"num_frames\"], info_dict[\"num_analyzed_body_parts\"])\n",
    "    pose_dict[\"y_coords\"] = pts_array_3d[:,1].reshape(\n",
    "            info_dict[\"num_frames\"], info_dict[\"num_analyzed_body_parts\"])\n",
    "    pose_dict[\"z_coords\"] = pts_array_3d[:,2].reshape(\n",
    "            info_dict[\"num_frames\"], info_dict[\"num_analyzed_body_parts\"])\n",
    "    return pose_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refill_nan_array(pts_array_clean, info_dict, dimension):\n",
    "    '''we take our chopped array and embedd it in a full array with nans'''\n",
    "    if dimension == '3d':\n",
    "        pts_refill = np.empty((info_dict[\"num_frames\"]*\n",
    "                               info_dict[\"num_analyzed_body_parts\"],3))\n",
    "        pts_refill[:] = np.NaN\n",
    "        pts_refill[info_dict[\"clean_point_indices\"],:] = pts_array_clean\n",
    "    else:\n",
    "        pts_all_flat = np.arange(info_dict[\"num_frames\"]*\n",
    "                               info_dict[\"num_analyzed_body_parts\"])\n",
    "        indices_init = np.concatenate([pts_all_flat,pts_all_flat])\n",
    "\n",
    "        pts_refill = np.empty((info_dict[\"num_frames\"]*\n",
    "                               info_dict[\"num_analyzed_body_parts\"]*\n",
    "                               info_dict[\"num_cameras\"],2))\n",
    "        pts_refill[:] = np.NaN\n",
    "        pts_refill[np.isin(indices_init, \n",
    "                           info_dict[\"clean_point_indices\"]),:] = pts_array_clean\n",
    "    return pts_refill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arr_2d_to_list_of_dicts(pts_array_2d, info_dict):\n",
    "    '''this works assuming that you flattened the x,y coords from the dataframe.'''\n",
    "    coord_list_of_dicts = []\n",
    "    for cam in range(info_dict[\"num_cameras\"]):\n",
    "        \n",
    "        row_indices = np.arange(cam*(pts_array_2d.shape[0]/info_dict[\"num_cameras\"]),\n",
    "          (cam+1)*(pts_array_2d.shape[0]/info_dict[\"num_cameras\"])).astype(int)\n",
    "        \n",
    "        coord_dict = {}\n",
    "        coord_dict[\"x_coords\"] = pts_array_2d[row_indices,0].reshape(\n",
    "                    info_dict[\"num_frames\"],  info_dict[\"num_analyzed_body_parts\"])\n",
    "        coord_dict[\"y_coords\"] = pts_array_2d[row_indices,1].reshape(\n",
    "                     info_dict[\"num_frames\"], info_dict[\"num_analyzed_body_parts\"])\n",
    "        \n",
    "        coord_list_of_dicts.append(coord_dict)\n",
    "    return coord_list_of_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "data_folder = 'mouseRunningData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DLC_dframe = pd.read_csv(data_folder + '/CollectedData_.csv', \n",
    "                         header = [1,2]) \n",
    "# header = [1,2] is important. Provides a hierarchical data frame\n",
    "DLC_dframe.head() # inspect\n",
    "#DLC_dframe['paw1LH_top','x'] # that's how you index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the bodyparts, coords entries.\n",
    "DLC_dframe = DLC_dframe.rename(columns = { \\\n",
    "    \"bodyparts\":\"img_name\", \"coords\":\"img_name\" })\n",
    "DLC_dframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bodyparts = list(DLC_dframe.columns.levels[0][1:]) # [1:] to remove img name\n",
    "print(bodyparts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(image_path, flip):\n",
    "    '''if necessary, we can flip to make it easier to plot on top of the image.'''\n",
    "    im = mpimg.imread(image_path)\n",
    "    if flip:\n",
    "        im = np.flipud(im)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image_array(img_indexes, flip):\n",
    "    im_shape = read_image(img_indexes[0], flip).shape # read first img\n",
    "    num_frames = len(img_indexes)\n",
    "    img_array = np.zeros((im_shape[0], im_shape[1], num_frames))\n",
    "    print(img_array.shape)\n",
    "    for i in range(num_frames):\n",
    "        img_array[:,:,i] = read_image(img_indexes[i], flip) # function defined above\n",
    "\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_images = data_folder + \\\n",
    "                '/' + \\\n",
    "                DLC_dframe[\"img_name\", \"img_name\"]\\\n",
    "                .to_numpy()\n",
    "print(path_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "im_arr = make_image_array(path_images,\n",
    "                             flip = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_labels(image, coord_list_of_dicts, index, color_list, ax = None):\n",
    "    '''ToDo: add multiple data sources, so instead of x_arr, y_arr have a list of dicts\n",
    "    with x,y coords. '''\n",
    "    nrows, ncols = image.shape\n",
    "    assert(len(color_list)==len(coord_list_of_dicts))\n",
    "    if ax == None:\n",
    "        plt.axis('off')\n",
    "        plt.imshow(image, 'gray')\n",
    "        plt.scatter(x_arr, y_arr)\n",
    "    else:\n",
    "        ax.axis('off')\n",
    "        ax.set_xlim(-10,ncols+10) # pad x,y axes\n",
    "        ax.set_ylim(nrows+10, -10)\n",
    "        ax.imshow(image, 'gray')\n",
    "        for i in range(len(coord_list_of_dicts)):\n",
    "            ax.scatter(coord_list_of_dicts[i][\"x_coords\"][index,:], \n",
    "                       coord_list_of_dicts[i][\"y_coords\"][index,:],\n",
    "                      color = color_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3d_points(coord_list_of_dicts,\n",
    "                   lims_dict,\n",
    "                   index,\n",
    "                   color_list,\n",
    "                   ax):\n",
    "    '''plot a single frame\n",
    "    ToDo: specify plotting patams, allow for multiple inputs'''\n",
    "    \n",
    "    assert(len(color_list)==len(coord_list_of_dicts))\n",
    "\n",
    "    ax.set_xlim3d(lims_dict[\"x\"])\n",
    "    ax.set_ylim3d(lims_dict[\"y\"])\n",
    "    ax.set_zlim3d(lims_dict[\"z\"])\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    \n",
    "    for i in range(len(coord_list_of_dicts)):\n",
    "        ax.plot(coord_list_of_dicts[i][\"x_coords\"][index,:], \\\n",
    "                coord_list_of_dicts[i][\"y_coords\"][index,:], \\\n",
    "                coord_list_of_dicts[i][\"z_coords\"][index,:],\n",
    "                linestyle = 'None', \n",
    "                marker = 'o', \n",
    "                color = color_list[i], markersize=4, label = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # older, worked\n",
    "# def plot_3d_points(x_coords, \n",
    "#                    y_coords, \n",
    "#                    z_coords, \n",
    "#                    lims_dict,\n",
    "#                    color,\n",
    "#                    ax):\n",
    "#     '''plot a single frame\n",
    "#     ToDo: specify plotting patams, allow for multiple inputs'''\n",
    "    \n",
    "#     ax.set_xlim3d(lims_dict[\"x\"])\n",
    "#     ax.set_ylim3d(lims_dict[\"y\"])\n",
    "#     ax.set_zlim3d(lims_dict[\"z\"])\n",
    "#     ax.set_xlabel('X')\n",
    "#     ax.set_ylabel('Y')\n",
    "#     ax.set_zlabel('Z')\n",
    "    \n",
    "#     ax.plot(x_coords, \\\n",
    "#             y_coords, \\\n",
    "#             z_coords,\n",
    "#             color=color, lw = 1, markersize=4, label = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pick either all body parts or part of them\n",
    "#bp2plot = ['nose_bot', 'nose_top', 'tailBase_bot', 'tailBase_top']\n",
    "bp2plot = bodyparts\n",
    "pose_2D_dict = {}\n",
    "pose_2D_dict[\"x_coords\"] = DLC_dframe.loc[: , (bp2plot , 'x')].to_numpy() # DLC_dframe[bp2plot]\n",
    "pose_2D_dict[\"y_coords\"] = DLC_dframe.loc[: , (bp2plot , 'y')].to_numpy() # DLC_dframe[bp2plot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# using https://stackoverflow.com/questions/12897374/get-unique-values-from-a-list-in-python\n",
    "'''just these body parts that are seen from both views.'''\n",
    "bp2plot = bodyparts\n",
    "bp_short = []\n",
    "for i in range(len(bp2plot)):\n",
    "    if bp2plot[i][:3] != 'obs': # not plotting the obstacle\n",
    "        bp_short.append(bp2plot[i][:-4]) # last four chars (_top/_bot)\n",
    "\n",
    "short_list = list(set(bp_short)) # set returns unique elements in list\n",
    "short_list_bot = []\n",
    "short_list_top = []\n",
    "for i in short_list:\n",
    "    short_list_bot.append(i + '_bot')\n",
    "    short_list_top.append(i + '_top')\n",
    "\n",
    "tuple_x= (short_list_bot, 'x')\n",
    "tuple_y= (short_list_bot, 'y')\n",
    "tuple_z = (short_list_top, 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract 3d from rick\n",
    "pose_dict_3d = {}\n",
    "pose_dict_3d[\"x_coords\"] = DLC_dframe.loc[: , \\\n",
    "                            tuple_x].to_numpy() # DLC_dframe[bp2plot]\n",
    "pose_dict_3d[\"y_coords\"] = DLC_dframe.loc[: , \\\n",
    "                            tuple_y].to_numpy() #/ DLC_dframe[bp2plot]\n",
    "pose_dict_3d[\"z_coords\"] = DLC_dframe.loc[: , \\\n",
    "                           tuple_z].to_numpy() # DLC_dframe[bp2plot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transform to BA format\n",
    "pts_array_3d = np.hstack([pose_dict_3d[\"x_coords\"].flatten().reshape(-1,1), \n",
    "           pose_dict_3d[\"y_coords\"].flatten().reshape(-1,1),\n",
    "                         pose_dict_3d[\"z_coords\"].flatten().reshape(-1,1)])\n",
    "\n",
    "print('original number of unique pts was %d' % pts_array_3d.shape[0])\n",
    "nan_pts_3d = np.isnan(pts_array_3d).any(axis=1) # remove 3d points here and in each view\n",
    "print(nan_pts_3d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# removing_nans\n",
    "print('excluding %d tracked points!' % np.sum(nan_pts_3d==True)) # number of excluded 3d points.\n",
    "pts_array_3d_clean = pts_array_3d[~nan_pts_3d, :]\n",
    "pts_all_flat = np.arange(pts_array_3d.shape[0])\n",
    "clean_point_indices = pts_all_flat[~nan_pts_3d]\n",
    "\n",
    "#(clean_point_indices == np.where(~nan_pts_3d)).all() # True\n",
    "info_dict = {}\n",
    "info_dict[\"num_frames\"] = DLC_dframe.shape[0]\n",
    "info_dict[\"num_analyzed_body_parts\"] = len(short_list)\n",
    "info_dict[\"num_cameras\"] = 2\n",
    "info_dict[\"num_points_all\"] = pts_array_3d.shape[0]\n",
    "info_dict[\"clean_point_indices\"] = pts_all_flat[~nan_pts_3d]\n",
    "assert(info_dict[\"num_points_all\"] == \n",
    "           info_dict[\"num_frames\"]*info_dict[\"num_analyzed_body_parts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract params for BA. assuming all points are visible from the two cameras (even if nans)\n",
    "# only body parts that are visible in both views\n",
    "tuple_x_bot = (short_list_bot, 'x')\n",
    "tuple_y_bot = (short_list_bot, 'y')\n",
    "tuple_x_top = (short_list_top, 'x')\n",
    "tuple_y_top = (short_list_top, 'y')\n",
    "\n",
    "# hstack x,y\n",
    "pts_array_2d_bot_full = np.hstack([DLC_dframe.loc[: , \\\n",
    "        tuple_x_bot].to_numpy().flatten().reshape(-1,1),\n",
    "                             DLC_dframe.loc[: , \\\n",
    "        tuple_y_bot].to_numpy().flatten().reshape(-1,1)])\n",
    "\n",
    "# remove nan_pts_3d rows\n",
    "pts_array_2d_bot = pts_array_2d_bot_full[~nan_pts_3d, :]\n",
    "\n",
    "# hstack x,y, and remove nan_pts_3d rows.\n",
    "pts_array_2d_top_full = np.hstack([DLC_dframe.loc[: , \\\n",
    "        tuple_x_top].to_numpy().flatten().reshape(-1,1),\n",
    "                             DLC_dframe.loc[: , \\\n",
    "        tuple_y_top].to_numpy().flatten().reshape(-1,1)])\n",
    "\n",
    "pts_array_2d_top = pts_array_2d_top_full[~nan_pts_3d, :]\n",
    "\n",
    "print('shape of each 2d pt array is %s and %s' %(\n",
    "    str(pts_array_2d_bot.shape),\n",
    "    str(pts_array_2d_top.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # concat 2d pts, concat pt indices first bot, then top. \n",
    "pts_array_2d = np.vstack([pts_array_2d_bot, pts_array_2d_top]) # bot first, top second.\n",
    "#point_indices = np.concatenate([pt_indices_bot, pt_indices_top])\n",
    "camera_indices = np.concatenate([np.zeros(pts_array_2d_bot.shape[0]),\n",
    "                           np.ones(pts_array_2d_top.shape[0])]).astype(int) # bot = cam0, top = cam1\n",
    "point_indices = np.tile(np.arange(pts_array_2d_bot.shape[0])\n",
    "                        ,2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test that you can go back and forth between chopped arr and full arr with nans\n",
    "# array_3d_back = refill_nan_array(pts_array_3d_clean, \n",
    "#                               info_dict, \n",
    "#                               dimension = '3d')\n",
    "# pose_dict_3d_refill = ordered_arr_3d_to_dict(array_3d_back, info_dict)\n",
    "# plt.scatter(pose_dict_3d_refill[\"z_coords\"][:,0], pose_dict_3d[\"z_coords\"][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array_2d_back = refill_nan_array(pts_array_2d, \n",
    "#                               info_dict, \n",
    "#                                dimension = '2d')\n",
    "# pose_list_2d_refill = arr_2d_to_list_of_dicts(array_2d_back,\n",
    "#                                               info_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to do\n",
    "1. sort file names by their integer. make sure that 1,2 ... 10 and not 1,10,2...\n",
    "2. make sure you can load images and plot them as video using open cv / ffmpeg.\n",
    "3. when this is done, we move to the format of creating single figures, saving these as images, and writing a movie.\n",
    "4. this is in order to abstract the code a little bit and have one module for each of the following:\n",
    "5. scatter points on an image.\n",
    "6. create figures per trace.\n",
    "7. 4.3. 3D plotting of objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # these are not the same data!\n",
    "# plt.scatter(dict_test[\"y_coords\"][:,0], \n",
    "#             pts_2d_dict_bot_full[\"y_coords\"][:,0])\n",
    "# # utils_IO.revert_ordered_arr_2d_to_dict doesn't work in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_start = 155 # will grab barObstacleScaling1/img(ind_start-1).png\n",
    "num_frames = 250\n",
    "ind_end = ind_start + num_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are padding the limits of the axis since some points lie at the border.\n",
    "pad = 10\n",
    "lims = {}\n",
    "lims[\"x\"], lims[\"y\"], lims[\"z\"] = \\\n",
    "        [np.nanmin(pose_dict_3d[\"x_coords\"])-pad, \\\n",
    "         np.nanmax(pose_dict_3d[\"x_coords\"])+pad], \\\n",
    "        [np.nanmin(pose_dict_3d[\"y_coords\"])-pad, \\\n",
    "         np.nanmax(pose_dict_3d[\"y_coords\"])+pad], \\\n",
    "        [np.nanmin(pose_dict_3d[\"z_coords\"])-pad, \\\n",
    "         np.nanmax(pose_dict_3d[\"z_coords\"])+pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lims[\"x\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solve the problem of the nans here, before any optimization.\n",
    "let's see if we can go back from our observation removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_3d = np.copy(pts_array_3d_clean)\n",
    "points_2d = np.copy(pts_array_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# init camera_params\n",
    "camera_params = 0.5+np.random.rand(2,9) # was 2 +\n",
    "camera_params[:,-2:] = np.zeros((2,2)) # init with zero distort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_cameras = camera_params.shape[0]\n",
    "n_points = points_3d.shape[0]\n",
    "n_frames = DLC_dframe.shape[0]\n",
    "\n",
    "n = 9 * n_cameras + 3 * n_points\n",
    "m = 2 * points_2d.shape[0]\n",
    "\n",
    "print(\"n_cameras: {}\".format(n_cameras))\n",
    "#print(\"n_frames: {}\".format(n_frames)) # recall three points per frame\n",
    "print(\"n_points: {}\".format(n_points))\n",
    "print(\"Total number of parameters: {}\".format(n))\n",
    "print(\"Total number of residuals: {}\".format(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x0 = np.hstack((camera_params.ravel(), points_3d.ravel()))\n",
    "f0 = utils_BA.fun(x0, n_cameras, n_points, camera_indices, point_indices, points_2d)\n",
    "plt.plot(f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "A = utils_BA.bundle_adjustment_sparsity(\n",
    "    n_cameras, n_points, camera_indices, point_indices)\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from scipy.optimize import least_squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "res = least_squares(utils_BA.fun, x0, jac_sparsity=A, \n",
    "                    verbose=2, x_scale='jac', \n",
    "                    ftol=1e-4, method='trf',\n",
    "                    args=(n_cameras, n_points, \n",
    "                          camera_indices, \n",
    "                          point_indices, points_2d))\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Optimization took {0:.0f} seconds\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "camera_params = res.x[:n_cameras * 9].reshape((n_cameras, 9))\n",
    "points_3d = res.x[n_cameras * 9:].reshape((n_points, 3))\n",
    "points_proj = utils_BA.project(points_3d[point_indices], camera_params[camera_indices])\n",
    "print('points_proj: ', points_proj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_folder = 'rick_plots'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(f0, label = 'pre optim, random init')\n",
    "plt.plot(res.fun, label = 'after optim')\n",
    "plt.legend()\n",
    "plt.ylabel('coordinate-wise signed reproj-error')\n",
    "#plt.xlabel('3 points X 1500 frames X 2 cameras X 2 coords')\n",
    "plt.title('reprojection error before and after optim')\n",
    "plt.savefig(os.path.join(plot_folder,'reproj-err-per-frame-initdlc3d.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.scatter(points_2d[:,0], points_proj[:,0])\n",
    "plt.plot(points_2d[:,0], points_2d[:,0], 'k')\n",
    "plt.xlabel('DLC 2d')\n",
    "plt.ylabel('re-projection')\n",
    "plt.title('x coord.')\n",
    "plt.subplot(122)\n",
    "plt.title('y coord.')\n",
    "plt.scatter(points_2d[:,1], points_proj[:,1])\n",
    "plt.plot(points_2d[:,1], points_2d[:,1], 'k')\n",
    "plt.savefig(os.path.join(plot_folder,'reprojection_scatter.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.isin(indices_init, clean_point_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now we first refill the full sized containers, then revert to dicts.\n",
    "\n",
    "# do the pts_array_3d_clean\n",
    "array_3d_back = refill_nan_array(pts_array_3d_clean, \n",
    "                               info_dict, \n",
    "                               dimension = '3d')\n",
    "\n",
    "pose_dict_3d_refill = ordered_arr_3d_to_dict(array_3d_back, info_dict)\n",
    "# pts_3d_BA\n",
    "BA_array_3d_back = refill_nan_array(points_3d, \n",
    "                               info_dict, \n",
    "                               dimension = '3d')\n",
    "BA_dict = ordered_arr_3d_to_dict(BA_array_3d_back, info_dict)\n",
    "\n",
    "# pts_2d_orig\n",
    "print('pts_array_2d: ', pts_array_2d.shape)\n",
    "array_2d_orig = refill_nan_array(pts_array_2d, \n",
    "                              info_dict, \n",
    "                               dimension = '2d')\n",
    "print('array_2d_orig: ', array_2d_orig.shape)\n",
    "pose_list_2d_orig = arr_2d_to_list_of_dicts(array_2d_orig,\n",
    "                                              info_dict)\n",
    "print('pose_list_2d_orig: ', pose_list_2d_orig[0]['x_coords'].shape)\n",
    "\n",
    "# pts_2d_reproj\n",
    "array_2d_reproj_back = refill_nan_array(points_proj, \n",
    "                              info_dict, \n",
    "                               dimension = '2d')\n",
    "pose_list_2d_reproj = arr_2d_to_list_of_dicts(array_2d_reproj_back,\n",
    "                                              info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_start = 155\n",
    "ind_end = 255 #355"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joined_list_2d = pose_list_2d_orig + pose_list_2d_reproj\n",
    "len(joined_list_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_list_3d = []\n",
    "joined_list_3d.append(pose_dict_3d_refill)\n",
    "joined_list_3d.append(BA_dict)\n",
    "len(joined_list_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(np.nanmin(np.array([joined_list_3d[0][\"x_coords\"].flatten(), \n",
    "          joined_list_3d[1][\"x_coords\"].flatten()])))\n",
    "print(np.nanmax(np.array([joined_list_3d[0][\"x_coords\"].flatten(), \n",
    "          joined_list_3d[1][\"x_coords\"].flatten()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list_2d = ['red', 'red', 'blue', 'blue']\n",
    "color_list_3d = ['red', 'blue']\n",
    "# set limits to be the maximum of the two plots\n",
    "# we are padding the limits of the axis since some points lie at the border.\n",
    "pad = 10\n",
    "lims = {}\n",
    "lims[\"x\"], lims[\"y\"], lims[\"z\"] = \\\n",
    "        [np.nanmin(np.array([joined_list_3d[0][\"x_coords\"].flatten(), \n",
    "          joined_list_3d[1][\"x_coords\"].flatten()]))-pad, \\\n",
    "         np.nanmax(np.array([joined_list_3d[0][\"x_coords\"].flatten(), \n",
    "          joined_list_3d[1][\"x_coords\"].flatten()])) +pad], \\\n",
    "        [np.nanmin(np.array([joined_list_3d[0][\"y_coords\"].flatten(), \n",
    "          joined_list_3d[1][\"y_coords\"].flatten()]))-pad, \\\n",
    "         np.nanmax(np.array([joined_list_3d[0][\"y_coords\"].flatten(), \n",
    "          joined_list_3d[1][\"y_coords\"].flatten()]))+pad], \\\n",
    "        [np.nanmin(np.array([joined_list_3d[0][\"z_coords\"].flatten(), \n",
    "          joined_list_3d[1][\"z_coords\"].flatten()]))-pad, \\\n",
    "         np.nanmax(np.array([joined_list_3d[0][\"z_coords\"].flatten(), \n",
    "          joined_list_3d[1][\"z_coords\"].flatten()]))+pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### 3d plot\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import mpl_toolkits.mplot3d.axes3d as p3\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(constrained_layout=True, figsize = (12,6))\n",
    "gs = GridSpec(2, 2, figure=fig)\n",
    "ax1 = fig.add_subplot(gs[:2, 0])\n",
    "ax2 = fig.add_subplot(gs[:2, 1], projection = '3d') # https://matplotlib.org/3.1.1/gallery/mplot3d/subplot3d.html\n",
    "image_folder = 'images_test'\n",
    "\n",
    "ax2.view_init(elev=0, azim=90) # see https://stackoverflow.com/questions/12904912/how-to-set-camera-position-for-3d-plots-using-python-matplotlib\n",
    "\n",
    "for i in range(ind_start,ind_end):\n",
    "    # clear both ax1 and ax2\n",
    "    ax1.cla()\n",
    "    ax2.cla()   \n",
    "    # load image\n",
    "    img = read_image(path_images[i], flip=False)\n",
    "   \n",
    "    plot_image_labels(img,\\\n",
    "                        joined_list_2d,\n",
    "                        i,\n",
    "                        color_list_2d,\n",
    "                        ax = ax1)\n",
    "    \n",
    "    ax2.azim += 1\n",
    "\n",
    "    plot_3d_points(joined_list_3d,\n",
    "                   lims,\n",
    "                   i,\n",
    "                   color_list_3d,\n",
    "                   ax=ax2)\n",
    "    im_int = str('%.5i' % i)\n",
    "    plt.savefig(image_folder + '/' + 'im' + im_int + '.png')\n",
    "    #plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make video from these images\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "im_list = os.listdir(image_folder)\n",
    "im_list.sort()\n",
    "im_list = im_list[1:]\n",
    " \n",
    "img_array = []\n",
    "for filename in im_list:\n",
    "    img = cv2.imread(os.path.join(image_folder, filename))\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    img_array.append(img)\n",
    "\n",
    "out = cv2.VideoWriter('video_test.mp4',\n",
    "                      cv2.VideoWriter_fourcc(*'DIVX'), \n",
    "                      10, size) # 15 fps\n",
    " \n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_images[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_dict2d_dlc = utils_IO.revert_ordered_arr_2d_to_dict(len(short_list), 2, pts_array_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_dict2d_dlc[0][\"x_coords\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_BA = {}\n",
    "result_BA[\"camera_params\"] = camera_params\n",
    "result_BA[\"points_3d\"] = points_3d\n",
    "result_BA[\"points_proj\"] = points_proj\n",
    "utils_IO.save_object(result_BA, 'BA_result_Rick_04_11')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Fundamental Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skew(vector):\n",
    "    \"\"\"\n",
    "    this function returns a numpy array with the skew symmetric cross product matrix for vector.\n",
    "    the skew symmetric cross product matrix is defined such that\n",
    "    np.cross(a, b) = np.dot(skew(a), b)\n",
    "\n",
    "    :param vector: An array like vector to create the skew symmetric cross product matrix for\n",
    "    :return: A numpy array of the skew symmetric cross product vector\n",
    "    \"\"\"\n",
    "\n",
    "    return np.array([[0, -vector[2], vector[1]], \n",
    "                     [vector[2], 0, -vector[0]], \n",
    "                     [-vector[1], vector[0], 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "#Bundle adjustment code: https://scipy-cookbook.readthedocs.io/items/bundle_adjustment.html\n",
    "\n",
    "# Get rotation vector\n",
    "rot_vec_1 = R.from_rotvec(camera_params[0, :3])\n",
    "R1 = rot_vec_1.as_matrix()\n",
    "#Get translation vector\n",
    "t1 = camera_params[0, 3:6]\n",
    "#Get focal length\n",
    "f1 = camera_params[0, 6]\n",
    "#Get intrinsic matrix\n",
    "K1 = np.asarray([[f1, 0, 0], [0, f1, 0], [0, 0, 1]]) ###Add offset\n",
    "\n",
    "#Repeat for view 2\n",
    "rot_vec_2 = R.from_rotvec(camera_params[1, :3])\n",
    "R2 = rot_vec_2.as_matrix()\n",
    "t2 = camera_params[1, 3:6]\n",
    "f2 = camera_params[1, 6]\n",
    "K2 = np.asarray([[f2, 0, 0], [0, f2, 0], [0, 0, 1]])\n",
    "\n",
    "# --- Now compute relevant quantities for F estimation ------\n",
    "#Camera matrix basics: http://www.cs.cmu.edu/~16385/s17/Slides/11.1_Camera_matrix.pdf\n",
    "#Fundamental matrix computation: https://rb.gy/dd0nz2\n",
    "\n",
    "#Compute projection matrices\n",
    "P1 = np.matmul(K1, np.concatenate((R1, t1[:, np.newaxis]), axis=1))\n",
    "P2 = np.matmul(K2, np.concatenate((R2, t2[:, np.newaxis]), axis=1))\n",
    "\n",
    "#Get camera center (view 1)\n",
    "R1_inv = np.linalg.inv(R1) \n",
    "C = np.matmul(-R1_inv, t1)\n",
    "C = np.append(C, 1)\n",
    "\n",
    "F = np.matmul(skew(np.matmul(P2, C)), np.matmul(P2, np.linalg.pinv(P1)))\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(ind_start,ind_end):\n",
    "    # load image\n",
    "    img = read_image(path_images[i], flip=False)\n",
    "    print(img.shape)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('msbr': conda)",
   "language": "python",
   "name": "python_defaultSpec_1598380748517"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}