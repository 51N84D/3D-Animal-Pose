{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import urllib\n",
    "import bz2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.image as mpimg\n",
    "from utils.utils_IO import ordered_arr_3d_to_dict, refill_nan_array, arr_2d_to_list_of_dicts, read_image, make_image_array, revert_ordered_arr_2d_to_dict, save_object\n",
    "from utils.utils_plotting import plot_image_labels, plot_3d_points\n",
    "from utils.utils_BA import fun, bundle_adjustment_sparsity, project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOP_IMG_HEIGHT=168\n",
    "BOT_IMG_HEIGHT=238\n",
    "IMG_WIDTH= 396\n",
    "P_X_BOT = P_X_TOP = IMG_WIDTH // 2\n",
    "P_Y_BOT = BOT_IMG_HEIGHT // 2\n",
    "P_Y_TOP = TOP_IMG_HEIGHT // 2\n",
    "#(Camera, Coordinates)\n",
    "#OFFSET = np.asarray([[P_Y_TOP, P_X_TOP], [P_Y_BOT, P_X_BOT]])\n",
    "OFFSET = np.asarray([[P_X_TOP, P_Y_TOP], [P_X_BOT, P_Y_BOT]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "data_folder = 'mouseRunningData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DLC_dframe = pd.read_csv(data_folder + '/CollectedData_.csv', \n",
    "                         header = [1,2]) \n",
    "# header = [1,2] is important. Provides a hierarchical data frame\n",
    "DLC_dframe.head() # inspect\n",
    "#DLC_dframe['paw1LH_top','x'] # that's how you index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the bodyparts, coords entries.\n",
    "DLC_dframe = DLC_dframe.rename(columns = { \\\n",
    "    \"bodyparts\":\"img_name\", \"coords\":\"img_name\" })\n",
    "DLC_dframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bodyparts = list(DLC_dframe.columns.levels[0][1:]) # [1:] to remove img name\n",
    "print(bodyparts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_images = data_folder + \\\n",
    "                '/' + \\\n",
    "                DLC_dframe[\"img_name\", \"img_name\"]\\\n",
    "                .to_numpy()\n",
    "print(path_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "im_arr = make_image_array(path_images[0:10], flip = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pick either all body parts or part of them\n",
    "#bp2plot = ['nose_bot', 'nose_top', 'tailBase_bot', 'tailBase_top']\n",
    "bp2plot = bodyparts\n",
    "pose_2D_dict = {}\n",
    "pose_2D_dict[\"x_coords\"] = DLC_dframe.loc[: , (bp2plot , 'x')].to_numpy() # DLC_dframe[bp2plot]\n",
    "pose_2D_dict[\"y_coords\"] = DLC_dframe.loc[: , (bp2plot , 'y')].to_numpy() # DLC_dframe[bp2plot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# using https://stackoverflow.com/questions/12897374/get-unique-values-from-a-list-in-python\n",
    "'''just these body parts that are seen from both views.'''\n",
    "bp2plot = bodyparts\n",
    "bp_short = []\n",
    "for i in range(len(bp2plot)):\n",
    "    if bp2plot[i][:3] != 'obs': # not plotting the obstacle\n",
    "        bp_short.append(bp2plot[i][:-4]) # last four chars (_top/_bot)\n",
    "\n",
    "short_list = list(set(bp_short)) # set returns unique elements in list\n",
    "short_list_bot = []\n",
    "short_list_top = []\n",
    "for i in short_list:\n",
    "    short_list_bot.append(i + '_bot')\n",
    "    short_list_top.append(i + '_top')\n",
    "\n",
    "tuple_x= (short_list_top, 'x')\n",
    "tuple_y= (short_list_top, 'y')\n",
    "tuple_z = (short_list_bot, 'y') #Remember to negate (right-hand-rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing / Re-mapping coordinates for bottom image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat bottom image separately\n",
    "# Remap y-values for bottom image\n",
    "DLC_dframe.loc[: , tuple_z] -= TOP_IMG_HEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract 3d from rick\n",
    "pose_dict_3d = {}\n",
    "pose_dict_3d[\"x_coords\"] = DLC_dframe.loc[: , \\\n",
    "                            tuple_x].to_numpy() # DLC_dframe[bp2plot]\n",
    "pose_dict_3d[\"y_coords\"] = DLC_dframe.loc[: , \\\n",
    "                            tuple_y].to_numpy() #/ DLC_dframe[bp2plot]\n",
    "\n",
    "pose_dict_3d[\"z_coords\"] = - DLC_dframe.loc[: , \\\n",
    "                           tuple_z].to_numpy()  # DLC_dframe[bp2plot]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transform to BA format\n",
    "pts_array_3d = np.hstack([pose_dict_3d[\"x_coords\"].flatten().reshape(-1,1), \n",
    "           pose_dict_3d[\"y_coords\"].flatten().reshape(-1,1),\n",
    "                         pose_dict_3d[\"z_coords\"].flatten().reshape(-1,1)])\n",
    "\n",
    "print('original number of unique pts was %d' % pts_array_3d.shape[0])\n",
    "nan_pts_3d = np.isnan(pts_array_3d).any(axis=1) # remove 3d points here and in each view\n",
    "print(nan_pts_3d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# removing_nans\n",
    "print('excluding %d tracked points!' % np.sum(nan_pts_3d==True)) # number of excluded 3d points.\n",
    "pts_array_3d_clean = pts_array_3d[~nan_pts_3d, :]\n",
    "pts_all_flat = np.arange(pts_array_3d.shape[0])\n",
    "clean_point_indices = pts_all_flat[~nan_pts_3d]\n",
    "\n",
    "#(clean_point_indices == np.where(~nan_pts_3d)).all() # True\n",
    "info_dict = {}\n",
    "info_dict[\"num_frames\"] = DLC_dframe.shape[0]\n",
    "info_dict[\"num_analyzed_body_parts\"] = len(short_list)\n",
    "info_dict[\"num_cameras\"] = 2\n",
    "info_dict[\"num_points_all\"] = pts_array_3d.shape[0]\n",
    "info_dict[\"clean_point_indices\"] = pts_all_flat[~nan_pts_3d]\n",
    "assert(info_dict[\"num_points_all\"] == \n",
    "           info_dict[\"num_frames\"]*info_dict[\"num_analyzed_body_parts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract params for BA. assuming all points are visible from the two cameras (even if nans)\n",
    "# only body parts that are visible in both views\n",
    "tuple_x_bot = (short_list_bot, 'x')\n",
    "tuple_y_bot = (short_list_bot, 'y')\n",
    "tuple_x_top = (short_list_top, 'x')\n",
    "tuple_y_top = (short_list_top, 'y')\n",
    "\n",
    "# hstack x,y\n",
    "pts_array_2d_bot_full = np.hstack([DLC_dframe.loc[: , \\\n",
    "        tuple_x_bot].to_numpy().flatten().reshape(-1,1),\n",
    "                             DLC_dframe.loc[: , \\\n",
    "        tuple_y_bot].to_numpy().flatten().reshape(-1,1)])\n",
    "\n",
    "# remove nan_pts_3d rows\n",
    "pts_array_2d_bot = pts_array_2d_bot_full[~nan_pts_3d, :]\n",
    "\n",
    "# hstack x,y, and remove nan_pts_3d rows.\n",
    "pts_array_2d_top_full = np.hstack([DLC_dframe.loc[: , \\\n",
    "        tuple_x_top].to_numpy().flatten().reshape(-1,1),\n",
    "                             DLC_dframe.loc[: , \\\n",
    "        tuple_y_top].to_numpy().flatten().reshape(-1,1)])\n",
    "\n",
    "pts_array_2d_top = pts_array_2d_top_full[~nan_pts_3d, :]\n",
    "\n",
    "print('shape of each 2d pt array is %s and %s' %(\n",
    "    str(pts_array_2d_bot.shape),\n",
    "    str(pts_array_2d_top.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # concat 2d pts, concat pt indices first bot, then top. \n",
    "pts_array_2d = np.vstack([pts_array_2d_bot, pts_array_2d_top]) # bot first, top second.\n",
    "#point_indices = np.concatenate([pt_indices_bot, pt_indices_top])\n",
    "camera_indices = np.concatenate([np.zeros(pts_array_2d_bot.shape[0]),\n",
    "                           np.ones(pts_array_2d_top.shape[0])]).astype(int) # bot = cam0, top = cam1\n",
    "point_indices = np.tile(np.arange(pts_array_2d_bot.shape[0])\n",
    "                        ,2).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to do\n",
    "1. sort file names by their integer. make sure that 1,2 ... 10 and not 1,10,2...\n",
    "2. make sure you can load images and plot them as video using open cv / ffmpeg.\n",
    "3. when this is done, we move to the format of creating single figures, saving these as images, and writing a movie.\n",
    "4. this is in order to abstract the code a little bit and have one module for each of the following:\n",
    "5. scatter points on an image.\n",
    "6. create figures per trace.\n",
    "7. 4.3. 3D plotting of objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_start = 155 # will grab barObstacleScaling1/img(ind_start-1).png\n",
    "num_frames = 255\n",
    "ind_end = ind_start + num_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are padding the limits of the axis since some points lie at the border.\n",
    "pad = 10\n",
    "lims = {}\n",
    "lims[\"x\"], lims[\"y\"], lims[\"z\"] = \\\n",
    "        [np.nanmin(pose_dict_3d[\"x_coords\"])-pad, \\\n",
    "         np.nanmax(pose_dict_3d[\"x_coords\"])+pad], \\\n",
    "        [np.nanmin(pose_dict_3d[\"y_coords\"])-pad, \\\n",
    "         np.nanmax(pose_dict_3d[\"y_coords\"])+pad], \\\n",
    "        [np.nanmin(pose_dict_3d[\"z_coords\"])-pad, \\\n",
    "         np.nanmax(pose_dict_3d[\"z_coords\"])+pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lims[\"x\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solve the problem of the nans here, before any optimization.\n",
    "let's see if we can go back from our observation removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_3d = np.copy(pts_array_3d_clean)\n",
    "points_2d = np.copy(pts_array_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# init camera_params\n",
    "#camera_params = np.random.rand(2,7) # was 2 +\n",
    "#camera_params[0,0:6] = 0\n",
    "camera_params = np.zeros((2,7)) # was 2 +\n",
    "#camera_params[:,-2:] = np.zeros((2,2)) # init with zero distort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_cameras = camera_params.shape[0]\n",
    "n_points = points_3d.shape[0]\n",
    "n_frames = DLC_dframe.shape[0]\n",
    "\n",
    "n = 7 * n_cameras + 3 * n_points\n",
    "m = 2 * points_2d.shape[0]\n",
    "\n",
    "print(\"n_cameras: {}\".format(n_cameras))\n",
    "#print(\"n_frames: {}\".format(n_frames)) # recall three points per frame\n",
    "print(\"n_points: {}\".format(n_points))\n",
    "print(\"Total number of parameters: {}\".format(n))\n",
    "print(\"Total number of residuals: {}\".format(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x0 = np.hstack((camera_params.ravel(), points_3d.ravel()))\n",
    "f0 = fun(x0, n_cameras, n_points, camera_indices, point_indices, points_2d, OFFSET)\n",
    "plt.plot(f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "A = bundle_adjustment_sparsity(\n",
    "    n_cameras, n_points, camera_indices, point_indices)\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from scipy.optimize import least_squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "res = least_squares(fun, x0, jac_sparsity=A, \n",
    "                    verbose=2, x_scale='jac', \n",
    "                    ftol=1e-4, method='trf',\n",
    "                    args=(n_cameras, n_points, \n",
    "                          camera_indices, \n",
    "                          point_indices, points_2d, OFFSET))\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Optimization took {0:.0f} seconds\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "camera_params = res.x[:n_cameras * 7].reshape((n_cameras, 7))\n",
    "points_3d = res.x[n_cameras * 7:].reshape((n_points, 3))\n",
    "points_proj = project(points_3d[point_indices], camera_params[camera_indices], OFFSET[camera_indices])\n",
    "print('points_proj: ', points_proj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "plot_folder = 'rick_plots'\n",
    "if not os.path.exists(plot_folder):\n",
    "    os.makedirs(plot_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(f0, label = 'pre optim, random init')\n",
    "plt.plot(res.fun, label = 'after optim')\n",
    "plt.legend()\n",
    "plt.ylabel('coordinate-wise signed reproj-error')\n",
    "#plt.xlabel('3 points X 1500 frames X 2 cameras X 2 coords')\n",
    "plt.title('reprojection error before and after optim')\n",
    "plt.savefig(os.path.join(plot_folder,'reproj-err-per-frame-initdlc3d.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.scatter(points_2d[:,0], points_proj[:,0])\n",
    "plt.plot(points_2d[:,0], points_2d[:,0], 'k')\n",
    "plt.xlabel('DLC 2d')\n",
    "plt.ylabel('re-projection')\n",
    "plt.title('x coord.')\n",
    "plt.subplot(122)\n",
    "plt.title('y coord.')\n",
    "plt.scatter(points_2d[:,1], points_proj[:,1])\n",
    "plt.plot(points_2d[:,1], points_2d[:,1], 'k')\n",
    "plt.savefig(os.path.join(plot_folder,'reprojection_scatter.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#np.isin(indices_init, clean_point_indices)\n",
    "print(short_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now we first refill the full sized containers, then revert to dicts.\n",
    "\n",
    "# do the pts_array_3d_clean\n",
    "array_3d_back = refill_nan_array(pts_array_3d_clean, \n",
    "                               info_dict, \n",
    "                               dimension = '3d')\n",
    "\n",
    "pose_dict_3d_refill = ordered_arr_3d_to_dict(array_3d_back, info_dict)\n",
    "# pts_3d_BA\n",
    "BA_array_3d_back = refill_nan_array(points_3d, \n",
    "                               info_dict, \n",
    "                               dimension = '3d')\n",
    "BA_dict = ordered_arr_3d_to_dict(BA_array_3d_back, info_dict)\n",
    "\n",
    "# pts_2d_orig\n",
    "print('pts_array_2d: ', pts_array_2d.shape)\n",
    "array_2d_orig = refill_nan_array(pts_array_2d, \n",
    "                              info_dict, \n",
    "                               dimension = '2d')\n",
    "print('array_2d_orig: ', array_2d_orig.shape)\n",
    "pose_list_2d_orig = arr_2d_to_list_of_dicts(array_2d_orig,\n",
    "                                              info_dict)\n",
    "print('pose_list_2d_orig: ', pose_list_2d_orig[0]['x_coords'].shape)\n",
    "\n",
    "# pts_2d_reproj\n",
    "array_2d_reproj_back = refill_nan_array(points_proj, \n",
    "                              info_dict, \n",
    "                               dimension = '2d')\n",
    "pose_list_2d_reproj = arr_2d_to_list_of_dicts(array_2d_reproj_back,\n",
    "                                              info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_start = 155\n",
    "ind_end = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joined_list_2d = pose_list_2d_orig + pose_list_2d_reproj\n",
    "len(joined_list_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_list_3d = []\n",
    "joined_list_3d.append(pose_dict_3d_refill)\n",
    "joined_list_3d.append(BA_dict)\n",
    "len(joined_list_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(np.nanmin(np.array([joined_list_3d[0][\"x_coords\"].flatten(), \n",
    "          joined_list_3d[1][\"x_coords\"].flatten()])))\n",
    "print(np.nanmax(np.array([joined_list_3d[0][\"x_coords\"].flatten(), \n",
    "          joined_list_3d[1][\"x_coords\"].flatten()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Red = ground truth, blue = proj\n",
    "color_list_2d = ['red', 'red', 'blue', 'blue']\n",
    "color_list_3d = ['red', 'blue']\n",
    "# set limits to be the maximum of the two plots\n",
    "# we are padding the limits of the axis since some points lie at the border.\n",
    "pad = 10\n",
    "lims = {}\n",
    "lims[\"x\"], lims[\"y\"], lims[\"z\"] = \\\n",
    "        [np.nanmin(np.array([joined_list_3d[0][\"x_coords\"].flatten(), \n",
    "          joined_list_3d[1][\"x_coords\"].flatten()]))-pad, \\\n",
    "         np.nanmax(np.array([joined_list_3d[0][\"x_coords\"].flatten(), \n",
    "          joined_list_3d[1][\"x_coords\"].flatten()])) +pad], \\\n",
    "        [np.nanmin(np.array([joined_list_3d[0][\"y_coords\"].flatten(), \n",
    "          joined_list_3d[1][\"y_coords\"].flatten()]))-pad, \\\n",
    "         np.nanmax(np.array([joined_list_3d[0][\"y_coords\"].flatten(), \n",
    "          joined_list_3d[1][\"y_coords\"].flatten()]))+pad], \\\n",
    "        [np.nanmin(np.array([joined_list_3d[0][\"z_coords\"].flatten(), \n",
    "          joined_list_3d[1][\"z_coords\"].flatten()]))-pad, \\\n",
    "         np.nanmax(np.array([joined_list_3d[0][\"z_coords\"].flatten(), \n",
    "          joined_list_3d[1][\"z_coords\"].flatten()]))+pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### 3d plot\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import mpl_toolkits.mplot3d.axes3d as p3\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(constrained_layout=True, figsize = (12,6))\n",
    "gs = GridSpec(2, 2, figure=fig)\n",
    "ax1 = fig.add_subplot(gs[:2, 0])\n",
    "ax2 = fig.add_subplot(gs[:2, 1], projection = '3d') # https://matplotlib.org/3.1.1/gallery/mplot3d/subplot3d.html\n",
    "image_folder = 'images_test'\n",
    "if not os.path.exists(image_folder):\n",
    "    os.makedirs(image_folder)\n",
    "\n",
    "ax2.view_init(elev=0, azim=90) # see https://stackoverflow.com/questions/12904912/how-to-set-camera-position-for-3d-plots-using-python-matplotlib\n",
    "\n",
    "for i in range(ind_start,ind_end):\n",
    "    # clear both ax1 and ax2\n",
    "    ax1.cla()\n",
    "    ax2.cla()   \n",
    "    # load image\n",
    "    img = read_image(path_images[i], flip=False)\n",
    "\n",
    "    plot_image_labels(img,\\\n",
    "                        joined_list_2d,\n",
    "                        i,\n",
    "                        color_list_2d,\n",
    "                        ax = ax1, top_img_height=TOP_IMG_HEIGHT)\n",
    "    \n",
    "    ax2.azim += 1\n",
    "\n",
    "    plot_3d_points(joined_list_3d,\n",
    "                   lims,\n",
    "                   i,\n",
    "                   color_list_3d,\n",
    "                   ax=ax2)\n",
    "    im_int = str('%.5i' % i)\n",
    "    plt.savefig(image_folder + '/' + 'im' + im_int + '.png')\n",
    "    #plt.show()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make video from these images\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "im_list = os.listdir(image_folder)\n",
    "im_list.sort()\n",
    "im_list = im_list[1:]\n",
    " \n",
    "img_array = []\n",
    "for filename in im_list:\n",
    "    img = cv2.imread(os.path.join(image_folder, filename))\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    img_array.append(img)\n",
    "\n",
    "out = cv2.VideoWriter('reconstruction.mp4',\n",
    "                      cv2.VideoWriter_fourcc(*'DIVX'), \n",
    "                      5, size) # 15 fps\n",
    " \n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_dict2d_dlc = revert_ordered_arr_2d_to_dict(len(short_list), 2, pts_array_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_dict2d_dlc[0][\"x_coords\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_BA = {}\n",
    "result_BA[\"camera_params\"] = camera_params\n",
    "result_BA[\"points_3d\"] = points_3d\n",
    "result_BA[\"points_proj\"] = points_proj\n",
    "save_object(result_BA, 'BA_result_Rick_04_11')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Fundamental Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skew(vector):\n",
    "    \"\"\"\n",
    "    this function returns a numpy array with the skew symmetric cross product matrix for vector.\n",
    "    the skew symmetric cross product matrix is defined such that\n",
    "    np.cross(a, b) = np.dot(skew(a), b)\n",
    "\n",
    "    :param vector: An array like vector to create the skew symmetric cross product matrix for\n",
    "    :return: A numpy array of the skew symmetric cross product vector\n",
    "    \"\"\"\n",
    "\n",
    "    return np.array([[0, -vector[2], vector[1]], \n",
    "                     [vector[2], 0, -vector[0]], \n",
    "                     [-vector[1], vector[0], 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "#Bundle adjustment code: https://scipy-cookbook.readthedocs.io/items/bundle_adjustment.html\n",
    "\n",
    "# Get rotation vector\n",
    "rot_vec_1 = R.from_rotvec(camera_params[0, :3])\n",
    "R1 = rot_vec_1.as_matrix()\n",
    "print(\"R1: \", R1)\n",
    "#Get translation vector\n",
    "t1 = camera_params[0, 3:6]\n",
    "print('t1: ', t1)\n",
    "#Get focal length\n",
    "f1 = camera_params[0, 6]\n",
    "#Get offsets\n",
    "p_x_1 = OFFSET[0, 0]\n",
    "p_y_1 = OFFSET[0, 1]\n",
    "\n",
    "print('f1: ', f1)\n",
    "print('p_x_1: ', p_x_1)\n",
    "print('p_y_1: ', p_y_1)\n",
    "\n",
    "#Get intrinsic matrix\n",
    "K1 = np.asarray([[f1, 0, p_x_1], [0, f1, p_y_1], [0, 0, 1]]) ###Add offset\n",
    "\n",
    "print('-------------')\n",
    "#Repeat for view 2\n",
    "rot_vec_2 = R.from_rotvec(camera_params[1, :3])\n",
    "R2 = rot_vec_2.as_matrix()\n",
    "print(\"R2: \", R2)\n",
    "t2 = camera_params[1, 3:6]\n",
    "print('t2: ', t2)\n",
    "f2 = camera_params[1, 6]\n",
    "print('f2: ', f2)\n",
    "#amera_params[1, 3:6]\n",
    "f2 = camera_params[1, 6]\n",
    "p_x_2 = OFFSET[1, 0]\n",
    "p_y_2 = OFFSET[1, 1]\n",
    "print('p_x_2: ', p_x_2)\n",
    "print('p_y_2: ', p_y_2)\n",
    "\n",
    "K2 = np.asarray([[f2, 0, p_x_2], [0, f2, p_y_2], [0, 0, 1]])\n",
    "\n",
    "# --- Now compute relevant quantities for F estimation ------\n",
    "#Camera matrix basics: http://www.cs.cmu.edu/~16385/s17/Slides/11.1_Camera_matrix.pdf\n",
    "#Fundamental matrix computation: https://rb.gy/dd0nz2\n",
    "\n",
    "#Compute projection matrices\n",
    "P1 = np.matmul(K1, np.concatenate((R1, t1[:, np.newaxis]), axis=1))\n",
    "P2 = np.matmul(K2, np.concatenate((R2, t2[:, np.newaxis]), axis=1))\n",
    "\n",
    "#Get camera center (view 1)\n",
    "R1_inv = np.linalg.inv(R1) \n",
    "C = np.matmul(-R1_inv, t1)\n",
    "C = np.append(C, 1)\n",
    "\n",
    "F = np.matmul(skew(np.matmul(P2, C)), np.matmul(P2, np.linalg.pinv(P1)))\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_circles(img, points):\n",
    "    for point in points:\n",
    "        cv2.circle(img,(point[0], point[1]), 10, (255,0,255), -1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope(x1,y1,x2,y2):\n",
    "    ###finding slope\n",
    "    if x2!=x1:\n",
    "        return((y2-y1)/(x2-x1))\n",
    "    else:\n",
    "        return 'NA'\n",
    "\n",
    "def drawLine(image,x1,y1,x2,y2):\n",
    "\n",
    "    m=slope(x1,y1,x2,y2)\n",
    "    h,w=image.shape[:2]\n",
    "    if m!='NA':\n",
    "        ### here we are essentially extending the line to x=0 and x=width\n",
    "        ### and calculating the y associated with it\n",
    "        ##starting point\n",
    "        px=0\n",
    "        py=-(x1-0)*m+y1\n",
    "        ##ending point\n",
    "        qx=w\n",
    "        qy=-(x2-w)*m+y2\n",
    "    else:\n",
    "    ### if slope is zero, draw a line with x=x1 and y=0 and y=height\n",
    "        px,py=x1,0\n",
    "        qx,qy=x1,h\n",
    "    image = cv2.line(image, (int(px), int(py)), (int(qx), int(qy)), (255, 255, 255), 2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epipolar_folder = './epipolar_lines/'\n",
    "if not os.path.exists(epipolar_folder):\n",
    "    os.makedirs(epipolar_folder)\n",
    "\n",
    "for i in range(ind_start,ind_end):\n",
    "    # load image\n",
    "    img = read_image(path_images[i], flip=False)\n",
    "    top_img = (img[0:TOP_IMG_HEIGHT, :] * 255).astype(np.uint8)\n",
    "    bottom_img = (img[TOP_IMG_HEIGHT:, :] * 255).astype(np.uint8)\n",
    "    \n",
    "    #Recall, indices 0 and 2 correspond to bottom image\n",
    "    x_t = joined_list_2d[1]['x_coords'][i][:,np.newaxis]\n",
    "    y_t = joined_list_2d[1]['y_coords'][i][:,np.newaxis]\n",
    "\n",
    "    x_b = joined_list_2d[0]['x_coords'][i][:,np.newaxis]\n",
    "    y_b = joined_list_2d[0]['y_coords'][i][:,np.newaxis]\n",
    "\n",
    "    points_top = np.concatenate((x_t,y_t), axis=1)\n",
    "    points_bot = np.concatenate((x_b,y_b), axis=1)\n",
    "\n",
    "    \n",
    "    #Get rid of nans\n",
    "    \n",
    "    points_bot = points_bot.astype(np.int32)\n",
    "    points_bot = points_bot[~np.isnan(points_bot).any(axis=1)]\n",
    "\n",
    "    points_top = points_top.astype(np.int32)\n",
    "    points_top = points_top[~np.isnan(points_top).any(axis=1)]\n",
    "\n",
    "\n",
    "    top_img_with_points = draw_circles(top_img, points_top)\n",
    "    bot_img_with_points = draw_circles(bottom_img, points_bot)\n",
    "    #cv2.imwrite('epipolar_lines/top_image_points.jpg', top_img_with_points)\n",
    "    #cv2.imwrite('epipolar_lines/bot_image_points.jpg', bot_img_with_points)\n",
    "\n",
    "    #Homogenize points\n",
    "    ones = np.ones(points_top.shape[0])[:,np.newaxis]\n",
    "    points_top_homog = np.concatenate((points_top, ones), axis=-1)\n",
    "    points_bot_homog = np.concatenate((points_bot, ones), axis=-1)\n",
    "    \n",
    "    aug_F = np.tile(F, (points_top_homog.shape[0], 1, 1))\n",
    "    lines_bot = np.squeeze(np.matmul(aug_F, points_top_homog[:,:,np.newaxis]))\n",
    "    #This^ gives us lines as vectors [a,b,c] --> ax + by + c = 0\n",
    "\n",
    "    for line_vec in lines_bot:\n",
    "        #Get x and y intercepts (on image) to plot\n",
    "\n",
    "        #y = 0: x = -c/a\n",
    "        x_intercept = int(-line_vec[2] / line_vec[0])\n",
    "        #x = 0: y = -c/b\n",
    "        y_intercept = int(-line_vec[2] / line_vec[1])\n",
    "        bottom_img = drawLine(bottom_img, x_intercept, 0, 0, y_intercept)\n",
    "        #bottom_img = cv2.line(bottom_img, (x_intercept, 0), (0, y_intercept), (255, 255, 255), thickness=1)\n",
    "\n",
    "\n",
    "\n",
    "    cv2.imwrite(f'epipolar_lines/bot_{i}.jpg', bottom_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_list = os.listdir(epipolar_folder)\n",
    "im_list.sort()\n",
    "im_list = im_list[1:]\n",
    " \n",
    "img_array = []\n",
    "for filename in im_list:\n",
    "    img = cv2.imread(os.path.join(epipolar_folder, filename))\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    img_array.append(img)\n",
    "    \n",
    "out = cv2.VideoWriter('epipolar_video.mp4',\n",
    "                      cv2.VideoWriter_fourcc(*'DIVX'), \n",
    "                      5, size) # 15 fps\n",
    " \n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot camera coordinate systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import plotly.graph_objs as go\n",
    "\n",
    "def vector_plot(tvects,is_vect=True,orig=[0,0,0]):\n",
    "    \"\"\"Plot vectors using plotly\"\"\"\n",
    "\n",
    "    if is_vect:\n",
    "        if not hasattr(orig[0],\"__iter__\"):\n",
    "            coords = [[orig,np.sum([orig,v],axis=0)] for v in tvects]\n",
    "        else:\n",
    "            coords = [[o,np.sum([o,v],axis=0)] for o,v in zip(orig,tvects)]\n",
    "    else:\n",
    "        coords = tvects\n",
    "\n",
    "    data = []\n",
    "    names = ['x', 'y', 'z']\n",
    "    for i,c in enumerate(coords):\n",
    "        X1, Y1, Z1 = zip(c[0])\n",
    "        X2, Y2, Z2 = zip(c[1])\n",
    "        vector = go.Scatter3d(x = [X1[0],X2[0]],\n",
    "                              y = [Y1[0],Y2[0]],\n",
    "                              z = [Z1[0],Z2[0]],\n",
    "                              marker = dict(size = [0,5],\n",
    "                                            color = ['blue'],\n",
    "                                            line=dict(width=5,\n",
    "                                                      color='DarkSlateGrey')),\n",
    "                              name = names[i])\n",
    "        data.append(vector)\n",
    "\n",
    "    layout = go.Layout(\n",
    "             margin = dict(l = 4,\n",
    "                           r = 4,\n",
    "                           b = 4,\n",
    "                           t = 4)\n",
    "                  )\n",
    "    return data\n",
    "    #fig = go.Figure(data=data,layout=layout)\n",
    "    #fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "data_1 = vector_plot([R1[:,0],R1[:,1],R1[:,2]], orig=t1)\n",
    "data_2 = vector_plot([R2[:,0],R2[:,1],R2[:,2]], orig=t2)\n",
    "layout = go.Layout(\n",
    "            margin = dict(l = 4,\n",
    "                        r = 4,\n",
    "                        b = 4,\n",
    "                        t = 4)\n",
    "                )\n",
    "data = data_1 + data_2\n",
    "\n",
    "fig = go.Figure(data=data,layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('msbr': conda)",
   "language": "python",
   "name": "python_defaultSpec_1598814867541"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}